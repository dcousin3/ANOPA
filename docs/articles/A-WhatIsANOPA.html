<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>What is an Analysis of Proportions using the Anscombe Transform? • ANOPA</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="What is an Analysis of Proportions using the Anscombe Transform?">
<meta property="og:description" content="This vignette describes what an analysis of proportion is.
">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">ANOPA</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.1.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/A-WhatIsANOPA.html">What is an Analysis of Proportions using the Anscombe Transform?</a>
    </li>
    <li>
      <a href="../articles/B-DataFormatsForProportions.html">Data formats for proportions</a>
    </li>
    <li>
      <a href="../articles/C-ConfidenceIntervals.html">Confidence intervals with proportions</a>
    </li>
    <li>
      <a href="../articles/D-ArringtonExample.html">Analyzing proportions with the Arrington et al. 2002 example</a>
    </li>
    <li>
      <a href="../articles/E-ArcsineIsAsinine.html">Is the ArcSine transformation so asinine in the end?</a>
    </li>
    <li>
      <a href="../articles/F-TestingTypeIError.html">Testing type-I error rates</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/dcousin3/ANOPA/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>What is an Analysis of Proportions using the
Anscombe Transform?</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/dcousin3/ANOPA/blob/HEAD/../vignettes/A-WhatIsANOPA.Rmd" class="external-link"><code>../vignettes/A-WhatIsANOPA.Rmd</code></a></small>
      <div class="hidden name"><code>A-WhatIsANOPA.Rmd</code></div>

    </div>

    
    
<p>The <em>ANalysis Of Proportion using the Anscombe transform</em>
(ANOPA) is a framework for analyzing proportions (often written as
percentages) across groups or across measurements. This framework is
similar to the well-known ANOVA and uses the same general approach. It
allows analyzing <em>main effects</em> and <em>interaction effects.</em>
It also allow analyzing <em>simple effects</em> (in case of
interactions) as well as <em>orthogonal contrats</em> and
<em>post-hoc</em> tests. Further, ANOPA makes it easy to generate
proportion plots which includes confidence intervals, and to compute
<em>eta-square</em> as a measure of effect size. Finally, power planning
is easy within ANOPA.</p>
<div class="section level3">
<h3 id="a-basic-example">A basic example<a class="anchor" aria-label="anchor" href="#a-basic-example"></a>
</h3>
<p>As an example, suppose a study where three groups of participants are
tested on their ability to have an illumination according to the nature
of a distracting task. This example is found in .</p>
<p>The data can be given with 1s for those participants who experienced
an illumination and with 0s for those who didn’t. Thus, a table having
one line per participant giving the observations would look like:</p>
<table class="table">
<thead><tr class="header">
<th align="left">Condition of distraction</th>
<th>Illumination?</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Doing Crosswords</td>
<td>1</td>
</tr>
<tr class="even">
<td align="left">Doing Crosswords</td>
<td>0</td>
</tr>
<tr class="odd">
<td align="left">Doing Crosswords</td>
<td>0</td>
</tr>
<tr class="even">
<td align="left">…</td>
<td>…</td>
</tr>
<tr class="odd">
<td align="left">Doing Crosswords</td>
<td>1</td>
</tr>
<tr class="even">
<td align="left">Solving Sudokus</td>
<td>0</td>
</tr>
<tr class="odd">
<td align="left">Solving Sudokus</td>
<td>1</td>
</tr>
<tr class="even">
<td align="left">Solving Sudokus</td>
<td>1</td>
</tr>
<tr class="odd">
<td align="left">…</td>
<td>…</td>
</tr>
<tr class="even">
<td align="left">Solving Sudokus</td>
<td>0</td>
</tr>
<tr class="odd">
<td align="left">Performing chants</td>
<td>0</td>
</tr>
<tr class="even">
<td align="left">Performing chants</td>
<td>1</td>
</tr>
<tr class="odd">
<td align="left">…</td>
<td>…</td>
</tr>
<tr class="even">
<td align="left">Performing chants</td>
<td>0</td>
</tr>
<tr class="odd">
<td align="left">Controlling breath</td>
<td>1</td>
</tr>
<tr class="even">
<td align="left">Controlling breath</td>
<td>1</td>
</tr>
<tr class="odd">
<td align="left">…</td>
<td>…</td>
</tr>
<tr class="even">
<td align="left">Controlling breath</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>This long table can easily be reduced by “compiling” the results,
that is, by counting the numer of participants per group who experienced
and illumination. Because the group sizes may not be equal, counting the
number of participants in each group is also needed. We would then
observe</p>
<table class="table">
<colgroup>
<col width="24%">
<col width="36%">
<col width="39%">
</colgroup>
<thead><tr class="header">
<th align="left">Condition of distraction</th>
<th>Number of illumination</th>
<th>Group size</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Doing Crosswords</td>
<td>10</td>
<td>30</td>
</tr>
<tr class="even">
<td align="left">Solving Sudokus</td>
<td>14</td>
<td>22</td>
</tr>
<tr class="odd">
<td align="left">Performing chants</td>
<td>7</td>
<td>18</td>
</tr>
<tr class="even">
<td align="left">Controlling breath</td>
<td>5</td>
<td>27</td>
</tr>
</tbody>
</table>
<p>From these data, we may wonder if the four interventions are equally
likely to result in an illumination. Transforming the number of
illumination in percentage provide some indications that this may not be
the case:</p>
<table class="table">
<thead><tr class="header">
<th align="left">Condition of distraction</th>
<th>Percentage of illumination</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Doing Crosswords</td>
<td>33.3%</td>
</tr>
<tr class="even">
<td align="left">Solving Sudokus</td>
<td>63.6%</td>
</tr>
<tr class="odd">
<td align="left">Performing chants</td>
<td>38.9%</td>
</tr>
<tr class="even">
<td align="left">Controlling breath</td>
<td>18.5%</td>
</tr>
</tbody>
</table>
<p>In all likelihood, solving Sudokos puts participants in a better
mental disposition to have an illumination whereas controlling ones’
breath might be the worst intervention to favor illuminations.</p>
<p>But how can we be confident of the reliability of this observation?
The sample is fairly large (total sample size of 97) and the effect
seems important (percentages ranging from 18 to 64% are not showing
trivially small differences) so that we can expect decent statistical
power.</p>
<p>How do we proceed to formally test this? This is the purpose of
ANOPA.</p>
</div>
<div class="section level3">
<h3 id="the-rational-behind-the-test-optional">The rational behind the test (optional)<a class="anchor" aria-label="anchor" href="#the-rational-behind-the-test-optional"></a>
</h3>
<p>ANOPA makes the following operations transparent. Hence, if you are
not interested in the internals of an ANOPA, you can just skip to the
next section.</p>
<p>The general idea is to have an ANOVA-like procedure to analyse
proportions. One critical assumption in ANOVA is that the variances are
homogeneous, that is, constant across conditions. Sadly, this is not the
case of proportions. Indeed, proportions close to 0% or close to 100%
(floor and ceiling) are obtained when in the population, the true
proportions are small (or large; we consider the former scenario
hereafter, but the rational is symmetrical for large population
proportions). When this is the case, there is very little room to
observe in a sample a proportion much deviant from the population
proportion. For example if the population proportion is, say, 5%, then
in a sample of 20 participants, you cannot expect to observe frequencies
very far from 5%. A contrario, if the population true proportion is 50%,
then on a sample of 20 participants, a larger range of observed
proportions are possible. This simple illustration shows that the
possible variance in the scores are not homogeneous: few variance is
expected for extreme proportions and more variance is expceted for
proportions in the middle of the range (near 50%).</p>
<p>Because the purpose of the analysis is to see if the proportions
might be different, it means that we envision that they occupy some
range, and therefore, we cannot maintain that variances are homogeneous.
We therefore need a “variance-stabilizing” approach.</p>
<p>The purpose of the Anscombe transform (an extension of the arcsine
transform) is precisely this: replace proportions with an alternate
measure which has the same expected variance irrespective of the
population variance . Anscombe showed that the variance of this
transformed proportions is a constant <span class="math inline">\(1/(4
(n+1/2))\)</span> determined only by the number of observations. Thus,
we have a variance- stabilizing transformation. As an added bonus, not
only are the variances stabilized, but we actually know their values.
Hence, it is no longer necessary to estimate the “error term” in an
ANOVA. As the error term is known, the denominator of the ANOVA is
calculated without degrees of freedom (we set them to <span class="math inline">\(\infty\)</span> to denote this).</p>
<p>Recent works (see last section) confirms that this transformation is
actually the most accurate approximation we know to this day and that
there is very little room to find a more accurate transfomraiton.</p>
</div>
<div class="section level2">
<h2 id="analyzing-the-data">Analyzing the data<a class="anchor" aria-label="anchor" href="#analyzing-the-data"></a>
</h2>
<p>The dataset above can be found in a compiled format in the dataframe
<code>ArticleExample1</code>:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ArticleExample1</span></span></code></pre></div>
<pre><code><span><span class="co">##   DistractingTask nSuccess nParticipants</span></span>
<span><span class="co">## 1      Crosswords       10            30</span></span>
<span><span class="co">## 2          Sudoku       14            22</span></span>
<span><span class="co">## 3          Chants        7            18</span></span>
<span><span class="co">## 4          Breath        5            27</span></span></code></pre>
<p>(there are alternate formats for the data discussed in the vignette
<a href="../articles/B-DataFormatsForProportions.html">DataFormatsForProportions</a>.
As seen the group labels are given in column
<code>DistractingTask</code> whereas the observations are described in
<code>nSuccess</code> (the number of 1s) and <code>nParticipants</code>
(the number of observations, i.e., the number of 0s and 1s). To see the
results as proportions, divide the number of succcess by the number of
observations, for example</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ArticleExample1</span><span class="op">$</span><span class="va">nSuccess</span> <span class="op">/</span> <span class="va">ArticleExample1</span><span class="op">$</span><span class="va">nParticipants</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.3333333 0.6363636 0.3888889 0.1851852</span></span></code></pre>
<p>(multiply by 100 to have percentages rather than proportions.)</p>
<p>The analysis is very simply triggered by the following</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/anopa.html">anopa</a></span><span class="op">(</span> <span class="op">{</span><span class="va">nSuccess</span>; <span class="va">nParticipants</span><span class="op">}</span> <span class="op">~</span> <span class="va">DistractingTask</span>, <span class="va">ArticleExample1</span><span class="op">)</span></span></code></pre></div>
<p>The first argument is a formula which describes how the data are
presented (before the ~) and what are the factors in the design (after
the ~). Here, because the observations are actually described over two
colums (the number of 1s and the total number of participants in each
group), we use the <code>{s;n}</code> notation which can be read as “s
over n” (note the curly braces and the semi-colon which is not standard
notation in R). The second argument is the data frame, here in compiled
form.</p>
<p>You are done!</p>
<p>Please start (always start) with a plot.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/anopa_asn_trans1.html">anopaPlot</a></span><span class="op">(</span><span class="va">w</span><span class="op">)</span> </span></code></pre></div>
<div class="figure">
<img src="A-WhatIsANOPA_files/figure-html/unnamed-chunk-5-1.png" alt="**Figure 1**. The proportion of illumination as a function of the distracting task. Error bars show difference-adjusted 95% confidence intervals." width="384"><p class="caption">
<strong>Figure 1</strong>. The proportion of illumination as a function
of the distracting task. Error bars show difference-adjusted 95%
confidence intervals.
</p>
</div>
<p>This plot shows confidence intervals that are “difference adjusted” .
Such confidence intervals allows comparing between-conditions using the
golden rule: <em>if a result is not included in the confidence interval
of another score, then the two conditions are likely significantly
different</em>. In the above plot, we see that the Breath condition is
not included in the Sudoky condition, so that we can expect these two
conditions to differ significantly, and as such, the ANOPA to show a
significant rejection of the null hypothesis that all the proportion are
equal.</p>
<p>The ANOPA table is obtained as usual with <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> or
<code><a href="../reference/summarize.html">summarize()</a></code>:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/summarize.html">summarize</a></span><span class="op">(</span><span class="va">w</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                       MS  df        F       p correction    Fcorr pvalcorr</span></span>
<span><span class="co">## DistractingTask 0.036803   3 3.512416 0.01451   1.035704 3.391331 0.017144</span></span>
<span><span class="co">## Error           0.010478 Inf</span></span></code></pre>
<p>or if you just want the corrected statistics (recommended), with</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/corrected.html">corrected</a></span><span class="op">(</span><span class="va">w</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                       MS  df        F correction    Fcorr pvalcorr</span></span>
<span><span class="co">## DistractingTask 0.036803   3 3.512416   1.035704 3.391331 0.017144</span></span>
<span><span class="co">## Error           0.010478 Inf</span></span></code></pre>
<p>As seen, the (uncorrected) effect of the <em>Distracting Task</em> is
significant (<span class="math inline">\(F(3, \infty) = 3.51\)</span>,
<span class="math inline">\(p = .014\)</span>). Because for small
samples, the <em>F</em> distribution is biased up, an adjusted version
can be consulted (last three columns). The results is nearly the same
here (<span class="math inline">\(F(3, \infty) = 3.39\)</span>, <span class="math inline">\(p = 0.017\)</span>) because this sample is far
from being small. The correction is obtained with Williams’ method and
reduces the <em>F</em> by 3.6% (column <code>correction</code> shows
1.0357).</p>
</div>
<div class="section level2">
<h2 id="post-hoc-test">Post-hoc test<a class="anchor" aria-label="anchor" href="#post-hoc-test"></a>
</h2>
<p>The proportions can be further analyzed using a post-hoc test to
determine which pairs of distracting tasks have different proportions of
illumination. To that end, we use Tukey’s Honestly Significant
Difference (HSD) procedure.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># posthocProportions( w )  ## not yet bundled in the library</span></span></code></pre></div>
<p>As seen, the Breath condition differs significantly from the Sudoku
condition. Also the Crosswords condition also differs from the Sudoku
conditions. Thease are the only two conditions for which a difference
seems statistically warranted.</p>
<p>This is it. Enjoy!</p>
<p>The vignette <a href="../articles/D-ArringtonExample.html">ArringtonExample</a> examines
a real dataset where more than one factor is present.</p>
</div>
<div class="section level2">
<h2 id="a-common-confusion">A common confusion<a class="anchor" aria-label="anchor" href="#a-common-confusion"></a>
</h2>
<p>A common confusion with regards to proportions is to believe that
<em>mean proportion</em> is a proportion. In Warton and Hui 2011, we
also have <em>median proportions</em>. All these expresses confusion as
to what a proportion is.</p>
<p>A proportion <em>must</em> be based on 1s and 0s. Thus, if a group’s
score is a proportion, it means that all the members of that group have
been observed once, and were coded as 0 or 1.</p>
<p>If you have multiple observations per subject, and if the group’s
score is the mean of the subject’s proportion, then you are in an
un-pure scenario: your primary data (the subjects proportions) are
<em>not</em> 0 or 1 and therefore, analyzing this situation cannot be
done with ANOPA.</p>
<p>If, on the other hand, you consider that the repeated measurements of
each participant is a factor, then you can analyze the results with
ANOPA assuming that the factor “repetition of the measurement” is a
within-subject factor.</p>
<p>In the worst-case situation, if the participants were measured
multiple times, but you do not have access to the individual
measurements, then you may treat the proportions as being <em>means</em>
and run a standard ANOVA. However, keep in mind that this approach is
only warranted if you have a lot of measurements (owing to the central
limit theorem). With just a handful of measurements, well, no one can
help you…</p>
</div>
<div class="section level2">
<h2 id="why-infinite-degrees-of-freedom-optional">Why infinite degrees of freedom? (optional)<a class="anchor" aria-label="anchor" href="#why-infinite-degrees-of-freedom-optional"></a>
</h2>
<p>For some, this notation may seems bizzare, or arbitrary. However, it
is formally an exact notation. An equivalent notation relates the <span class="math inline">\(t\)</span> tests and the <span class="math inline">\(z\)</span> tests. As is well-known, the <span class="math inline">\(t\)</span> test is used when the population
variance<br>
is unknown and estimated from the sample’s variance. In this test, this
variance can be seen as the “error term”. However, when the population
variance is known, we can use this information and the test then becomes
a <span class="math inline">\(z\)</span> test. Yet, the <span class="math inline">\(t\)</span> distribution (and the critical value of
this test) is identical to a standardized Normal distribution when the
degrees of freedom in the <span class="math inline">\(t\)</span>
distribution tends to infinity. In other words, a <span class="math inline">\(z\)</span> test is the same as a <span class="math inline">\(t\)</span> test when there is no uncertainty in
the error term. And when there is no uncertainty in the error term, we
can replace the degrees of freedom with infinity.</p>
<p>This rationale is the same in the ANOPA which explains why we note
the denominator’s degree of freedom with infinity.</p>
</div>
<div class="section level2">
<h2 id="why-the-arcsin-transform-optional">Why the arcsin transform? (optional)<a class="anchor" aria-label="anchor" href="#why-the-arcsin-transform-optional"></a>
</h2>
<p>This transformation may seem quite arbitrary. Its origin shows indeed
that this solution was found by a vague intuition. Fisher is the first
to propose trigonometric transformations for the study of statistics in
1915. This approach was found fertile when applied to correlation
testing, where the arctan transform (formally, the inverse hyperbolic
tangent transformation) provided an excellent approximation .</p>
<p>When Fisher considered the proportions, his first attempt was to
suggest a cosine transform . Zubin later refined the approach by
suggesting the arcsine transform . The basic form of the arcsine
transform was later refined by Anscombe to the form we use in the ANOPA
. Anscombe modifications, the addition of 3/8 to the number of success
and 3/4 to the number of trials, led to a theoretical variance exactly
equal to <span class="math inline">\(1/(4 \times n)\)</span>.</p>
<p>Formidable development in the early 90s showed that this transform
has other important characteristics. For example, and derived that this
transform will either underestimate the true probability or overestimate
it. More importantly, Chen showed that no other transformation is known
to fluctuate less than the arcsine transform around the exact
probability. This transformation is therefore the best option when
analyzing proportions.</p>
<p>You can read more in <span class="citation">Laurencelle &amp;
Cousineau (2023)</span>; also check <span class="citation">Chen
(1990)</span> or <span class="citation">Lehman &amp; Loh (1990)</span>
mathematical demonstrations showing the robustness of the ANOA. Finally,
<span class="citation">Williams (1976)</span> explains the correction
factor and its purpose.</p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0" line-spacing="2">
<div id="ref-c90" class="csl-entry">
Chen, H. (1990). The accuracy of approximate intervals for a binomial
parameter. <em>Journal of the American Statistical Associtation</em>,
<em>85</em>, 514–518. <a href="https://doi.org/10.1080/01621459.1990.10476229" class="external-link">https://doi.org/10.1080/01621459.1990.10476229</a>
</div>
<div id="ref-lc23" class="csl-entry">
Laurencelle, L., &amp; Cousineau, D. (2023). Analysis of proportions
using arcsine transform with any experimental design. <em>Frontiers in
Psychology</em>, <em>13</em>, 1045436. <a href="https://doi.org/10.3389/fpsyg.2022.1045436" class="external-link">https://doi.org/10.3389/fpsyg.2022.1045436</a>
</div>
<div id="ref-ll90" class="csl-entry">
Lehman, E. L., &amp; Loh, W.-Y. (1990). Pointwise versus uniform
robustness of some large-sample tests and confidence intervals.
<em>Scandinavian Journal of Statistics</em>, <em>17</em>, 177–187.
</div>
<div id="ref-w76" class="csl-entry">
Williams, D. A. (1976). Improved likelihood ratio tests for complete
contingency tables. <em>Biometrika</em>, <em>63</em>(1), 33–37. <a href="https://doi.org/10.2307/2335081" class="external-link">https://doi.org/10.2307/2335081</a>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Denis Cousineau, Louis Laurencelle.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
