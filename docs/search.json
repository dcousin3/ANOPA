[{"path":"https://dcousin3.github.io/ANOPA/articles/A-WhatIsANOPA.html","id":"a-basic-example","dir":"Articles","previous_headings":"","what":"A basic example","title":"What is an Analysis of Proportions using the Anscombe Transform?","text":"example, suppose study three groups participants tested ability illumination according nature distracting task. example found . data can given 1s participants experienced illumination 0s didn’t. Thus, table one line per participant giving observations look like: long table can easily reduced “compiling” results, , counting number participants per group experienced illumination. group sizes may equal, counting number participants group also needed. observe data, may wonder four interventions equally likely result illumination. Transforming number illumination percentage provide indications may case: likelihood, solving Sudokus puts participants better mental disposition illumination whereas controlling ones’ breath might worst intervention favor illuminations. can confident reliability observation? sample fairly large (total sample size 97) effect seems important (percentages ranging 18 64% showing trivially small differences) can expect decent statistical power. proceed formally test ? purpose ANOPA.","code":""},{"path":"https://dcousin3.github.io/ANOPA/articles/A-WhatIsANOPA.html","id":"the-rational-behind-the-test-optional","dir":"Articles","previous_headings":"","what":"The rational behind the test (optional)","title":"What is an Analysis of Proportions using the Anscombe Transform?","text":"ANOPA makes following operations transparent. Hence, interested internals ANOPA, can just skip next section. general idea ANOVA-like procedure analyse proportions. One critical assumption ANOVA variances homogeneous, , constant across conditions. Sadly, case proportions. Indeed, proportions close 0% close 100% (floor ceiling) obtained population, true proportions small (large; consider former scenario hereafter, rational symmetrical large population proportions). case, little room observe sample proportion much deviant population proportion. example population proportion , say, 5%, sample 20 participants, expect observe frequencies far 5%. contrario, population true proportion 50%, sample 20 participants, larger range observed proportions possible. simple illustration shows possible variance scores homogeneous: variance expected extreme proportions variance expected proportions middle range (near 50%). purpose analysis see proportions might different, means envision occupy range, therefore, maintain variances homogeneous. therefore need “variance-stabilizing” approach. purpose Anscombe transform (extension arcsine transform) precisely : replace proportions alternate measure expected variance irrespective population variance . Anscombe showed variance transformed proportions constant 1/(4(n+1/2))1/(4 (n+1/2)) determined number observations. Thus, variance- stabilizing transformation. added bonus, variances stabilized, actually know values. Hence, longer necessary estimate “error term” ANOVA. error term known, denominator ANOVA calculated without degrees freedom (set ∞\\infty denote ). Recent works (see last section) confirms transformation actually accurate approximation know day little room find accurate transformation.","code":""},{"path":"https://dcousin3.github.io/ANOPA/articles/A-WhatIsANOPA.html","id":"analyzing-the-data","dir":"Articles","previous_headings":"","what":"Analyzing the data","title":"What is an Analysis of Proportions using the Anscombe Transform?","text":"dataset can found compiled format dataframe ArticleExample1: (alternate formats data discussed vignette DataFormatsForProportions. seen group labels given column DistractingTask whereas observations described nSuccess (number 1s) nParticipants (number observations, .e., number 0s 1s). see results proportions, divide number succcess number observations, example (multiply 100 percentages rather proportions.) analysis simply triggered following first argument formula describes data presented (~) factors design (~). , observations actually described two columns (number 1s total number participants group), use {s;n} notation can read “s n” (note curly braces semi-colon standard notation R). second argument data frame, compiled form. done! Please start (always start) plot. Figure 1. proportion illumination function distracting task. Error bars show difference-adjusted 95% confidence intervals. plot shows confidence intervals “difference adjusted” . confidence intervals allows comparing -conditions using golden rule: result included confidence interval another score, two conditions likely significantly different. plot, see Breath condition included Sudoku condition, can expect two conditions differ significantly, , ANOPA show significant rejection null hypothesis proportion equal. ANOPA table obtained usual summary() summarize(): just want corrected statistics (recommended), seen, (uncorrected) effect Distracting Task significant (F(3,∞)=3.51F(3, \\infty) = 3.51, p=.014p = .014). small samples, F distribution biased , adjusted version can consulted (last three columns). results nearly (F(3,∞)=3.39F(3, \\infty) = 3.39, p=0.017p = 0.017) sample far small. correction obtained Williams’ method reduces F 3.6% (column correction shows 1.0357).","code":"ArticleExample1 ##   DistractingTask nSuccess nParticipants ## 1      Crosswords       10            30 ## 2          Sudoku       14            22 ## 3          Chants        7            18 ## 4          Breath        5            27 ArticleExample1$nSuccess / ArticleExample1$nParticipants ## [1] 0.3333333 0.6363636 0.3888889 0.1851852 w <- anopa( {nSuccess; nParticipants} ~ DistractingTask, ArticleExample1) anopaPlot(w) summarize(w) ##                       MS  df        F       p correction    Fcorr pvalcorr ## DistractingTask 0.036803   3 3.512416 0.01451   1.035704 3.391331 0.017144 ## Error           0.010478 Inf corrected(w) ##                       MS  df        F correction    Fcorr pvalcorr ## DistractingTask 0.036803   3 3.512416   1.035704 3.391331 0.017144 ## Error           0.010478 Inf"},{"path":"https://dcousin3.github.io/ANOPA/articles/A-WhatIsANOPA.html","id":"post-hoc-test","dir":"Articles","previous_headings":"","what":"Post-hoc test","title":"What is an Analysis of Proportions using the Anscombe Transform?","text":"proportions can analyzed using post-hoc test determine pairs distracting tasks different proportions illumination. end, use Tukey’s Honestly Significant Difference (HSD) procedure. seen, Breath condition differs significantly Sudoku condition. Also Crosswords condition also differs Sudoku conditions. two conditions difference seems statistically warranted. . Enjoy! vignette ArringtonExample examines real dataset one factor present.","code":"# posthocProportions( w )  ## not yet bundled in the library"},{"path":"https://dcousin3.github.io/ANOPA/articles/A-WhatIsANOPA.html","id":"a-common-confusion","dir":"Articles","previous_headings":"","what":"A common confusion","title":"What is an Analysis of Proportions using the Anscombe Transform?","text":"common confusion regards proportions believe mean proportion proportion. Warton Hui 2011, also median proportions. expresses confusion proportion . proportion must based 1s 0s. Thus, group’s score proportion, means members group observed , coded 0 1. multiple observations per subject, group’s score mean subject’s proportion, un-pure scenario: primary data (subjects proportions) 0 1 therefore, analyzing situation done ANOPA. , hand, consider repeated measurements participant factor, can analyze results ANOPA assuming factor “repetition measurement” within-subject factor. worst-case situation, participants measured multiple times, access individual measurements, may treat proportions means run standard ANOVA. However, keep mind approach warranted lot measurements (owing central limit theorem). just handful measurements, well, one can help …","code":""},{"path":"https://dcousin3.github.io/ANOPA/articles/A-WhatIsANOPA.html","id":"why-infinite-degrees-of-freedom-optional","dir":"Articles","previous_headings":"","what":"Why infinite degrees of freedom? (optional)","title":"What is an Analysis of Proportions using the Anscombe Transform?","text":", notation may seems bizarre, arbitrary. However, formally exact notation. equivalent notation relates tt tests zz tests. well-known, tt test used population variance unknown estimated sample’s variance. test, variance can seen “error term”. However, population variance known, can use information test becomes zz test. Yet, tt distribution (critical value test) identical standardized Normal distribution degrees freedom tt distribution tends infinity. words, zz test tt test uncertainty error term. uncertainty error term, can replace degrees freedom infinity. rationale ANOPA explains note denominator’s degree freedom infinity.","code":""},{"path":"https://dcousin3.github.io/ANOPA/articles/A-WhatIsANOPA.html","id":"why-the-arcsine-transform-optional","dir":"Articles","previous_headings":"","what":"Why the arcsine transform? (optional)","title":"What is an Analysis of Proportions using the Anscombe Transform?","text":"transformation may seem quite arbitrary. origin shows indeed solution found vague intuition. Fisher first propose trigonometric transformations study statistics 1915. approach found fertile applied correlation testing, arctan transform (formally, inverse hyperbolic tangent transformation) provided excellent approximation (Fisher, 1921). Fisher considered proportions, first attempt suggest cosine transform . Zubin later refined approach suggesting arcsine transform . basic form arcsine transform refined Anscombe form use ANOPA (Anscombe, 1948). Anscombe modifications, addition 3/8 number success 3/4 number trials, led theoretical variance exactly equal 1/(4×n+2)1/(4 \\times n + 2). Formidable development early 90s showed transform important characteristics. example, Chen (1990) Lehman & Loh (1990) derived transform either underestimate true probability overestimate . importantly, Chen showed transformation known fluctuate less arcsine transform around exact probability. transformation therefore best option analyzing proportions. can read Laurencelle & Cousineau (2023); also check Chen (1990) Lehman & Loh (1990) mathematical demonstrations showing robustness ANOPA. Finally, Williams (1976) explains correction factor purpose.","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/articles/B-DataFormatsForProportions.html","id":"data-formats-for-proportions","dir":"Articles","previous_headings":"","what":"Data formats for proportions","title":"Data formats for proportions","text":"proportions actually raw data: proportion one response (typically called success) responses (responses called collectively failure). , proportion summary statistic, bit like mean summary statistic continuous data. often, success coded using digit 1 failure, digit 0. case, computing mean actually computing proportion successes. However, conceptual mistake think proportions means, must processed completely differently averages. example, standard error confidence intervals proportions obtained using different procedures standard error confidence intervals mean. vignette, review various ways data can coded data frame. nutshell, three ways represent success failures, Wide, Long, Compiled. first two shows raw scores whereas last shows summary data. begin, load package ANOPA (present computer, first upload computer CRAN source repository devtools::install_github(\"dcousin3/ANOPA\")):","code":"library(ANOPA)"},{"path":"https://dcousin3.github.io/ANOPA/articles/B-DataFormatsForProportions.html","id":"first-format-wide-data-format","dir":"Articles","previous_headings":"Data formats for proportions","what":"First format: Wide data format","title":"Data formats for proportions","text":"format, one line per subject one column measurements. columns contain 1s (success) 0s (`failure). participant measured multiple times, one () within-subject factor(s) resulting multiple columns measurements. -group design, single column scores. example, consider following data -subject factor design two factors: Class (2 levels) Difficulty (3 levels) 6 groups. identical number participants , 12, total 72 participants. data wide format, formula anopa() must provide columns success/failure stored, conditions usual ~, (dataWide1 obtained shown Section Converting formats .) another example, consider following example obtained mixed, within- - subject design. factor Status 8, 9 7 participants per group respectively. also four repeated measures, bpre, bpost, b1week b5week represent four different Moments measurements. data frame formula analyzing data format necessary () group measurement columns using cbind(); (b) indicate within-subject factor(s) using argument WSFactors along number levels string. Alternatively, cbind() can replaced crange() first last variable binded. -variables taken data.frame().","code":"dataWide1 ##    Class Difficulty success ## 1  First       Easy       1 ## 2  First       Easy       1 ## 3  First       Easy       1 ## 4  First       Easy       1 ## 5  First       Easy       1 ## 6  First       Easy       1 ## 7  First       Easy       1 ## 8  First       Easy       1 ## 9  First       Easy       1 ## 10 First       Easy       1 ## 11 First       Easy       1 ## 12 First       Easy       0 ## 13 First   Moderate       1 ## 14 First   Moderate       1 ## 15 First   Moderate       1 ## 16 First   Moderate       1 ## 17 First   Moderate       1 ## 18 First   Moderate       1 ## 19 First   Moderate       1 ## 20 First   Moderate       1 ## 21 First   Moderate       1 ## 22 First   Moderate       0 ## 23 First   Moderate       0 ## 24 First   Moderate       0 ## 25 First  Difficult       1 ## 26 First  Difficult       1 ## 27 First  Difficult       1 ## 28 First  Difficult       1 ## 29 First  Difficult       1 ## 30 First  Difficult       1 ## 31 First  Difficult       0 ## 32 First  Difficult       0 ## 33 First  Difficult       0 ## 34 First  Difficult       0 ## 35 First  Difficult       0 ## 36 First  Difficult       0 ## 37  Last       Easy       1 ## 38  Last       Easy       1 ## 39  Last       Easy       1 ## 40  Last       Easy       1 ## 41  Last       Easy       1 ## 42  Last       Easy       1 ## 43  Last       Easy       1 ## 44  Last       Easy       1 ## 45  Last       Easy       1 ## 46  Last       Easy       1 ## 47  Last       Easy       0 ## 48  Last       Easy       0 ## 49  Last   Moderate       1 ## 50  Last   Moderate       1 ## 51  Last   Moderate       1 ## 52  Last   Moderate       1 ## 53  Last   Moderate       1 ## 54  Last   Moderate       1 ## 55  Last   Moderate       1 ## 56  Last   Moderate       1 ## 57  Last   Moderate       0 ## 58  Last   Moderate       0 ## 59  Last   Moderate       0 ## 60  Last   Moderate       0 ## 61  Last  Difficult       1 ## 62  Last  Difficult       1 ## 63  Last  Difficult       1 ## 64  Last  Difficult       0 ## 65  Last  Difficult       0 ## 66  Last  Difficult       0 ## 67  Last  Difficult       0 ## 68  Last  Difficult       0 ## 69  Last  Difficult       0 ## 70  Last  Difficult       0 ## 71  Last  Difficult       0 ## 72  Last  Difficult       0 w1 <- anopa( success ~ Class * Difficulty, dataWide1) dataWide2 ##      Status bpre bpost b1week b5week ## 1    Broken    1     1      1      0 ## 2    Broken    1     1      0      0 ## 3    Broken    0     0      1      1 ## 4    Broken    1     1      1      1 ## 5    Broken    0     0      1      1 ## 6    Broken    1     0      1      1 ## 7    Broken    1     1      0      1 ## 8    Broken    0     1      1      0 ## 9  Repaired    1     1      0      0 ## 10 Repaired    0     1      0      1 ## 11 Repaired    1     1      0      0 ## 12 Repaired    0     0      1      0 ## 13 Repaired    0     0      0      0 ## 14 Repaired    1     0      0      0 ## 15 Repaired    0     0      0      0 ## 16 Repaired    0     0      0      1 ## 17 Repaired    0     0      1      0 ## 18      New    0     0      0      1 ## 19      New    0     0      1      0 ## 20      New    0     0      0      0 ## 21      New    0     0      1      0 ## 22      New    0     0      0      0 ## 23      New    0     1      0      0 ## 24      New    0     0      1      0 ## 25      New    1     1      0      0 ## 26      New    0     0      0      1 ## 27      New    1     1      1      0 w2 <- anopa( cbind(bpre, bpost, b1week, b5week) ~ Status, dataWide2, WSFactors = \"Moment(4)\" ) w2bis <- anopa( crange(bpre, b5week) ~ Status, dataWide2, WSFactors = \"Moment(4)\" )"},{"path":"https://dcousin3.github.io/ANOPA/articles/B-DataFormatsForProportions.html","id":"second-format-long-data-format","dir":"Articles","previous_headings":"Data formats for proportions","what":"Second format: Long data format","title":"Data formats for proportions","text":"format may preferred linear modelers (may rapidly becomes long!). always least columns: One Id column, one column indicate within-subject level, one column indicate observed score. hand, format fewer columns repeated measure designs. example shows first 6 lines 2-factor design data , stored long format. analyse data format within anopa(), use vertical line symbol indicates observations nested within Id (.e., lines Id actually subject). mixed design described , data begin : analyzed formula:","code":"##   Id Class Difficulty Variable Value ## 1  1 First       Easy  success     1 ## 2  2 First       Easy  success     1 ## 3  3 First       Easy  success     1 ## 4  4 First       Easy  success     1 ## 5  5 First       Easy  success     1 ## 6  6 First       Easy  success     1 w1Long <- anopa( Value ~ Class * Difficulty * Variable  | Id, dataLong1 ) head(dataLong2) ##   Id Status Variable Value ## 1  1 Broken     bpre     1 ## 2  1 Broken    bpost     1 ## 3  1 Broken   b1week     1 ## 4  1 Broken   b5week     0 ## 5  2 Broken     bpre     1 ## 6  2 Broken    bpost     1 w2Long <- anopa( Value ~ Status * Variable  | Id, dataLong2, WSFactors=\"Moment(4)\" )"},{"path":"https://dcousin3.github.io/ANOPA/articles/B-DataFormatsForProportions.html","id":"third-format-compiled-data-format","dir":"Articles","previous_headings":"Data formats for proportions","what":"Third format: Compiled data format","title":"Data formats for proportions","text":"format compiled, sense 0s 1s replaced single count success cell design. Hence, longer access raw data. format however advantage compact, requiring lines. data 2 -subject factors example use compiled format anopa(), use succes identifies column total number successes stored. column Count indicates total number observations cell. notation {s;n} read s n (note curly braces semicolon). mixed design presented earlier, data looks like: columns number success repeated measures. new columns appear uAlpha. column (called unitary alpha) measure correlation (-1 +1). fictitious example, correlations near zero (negative actually) chance data generated randomly. run ANOPA compiled data repeated measures, use cbind() lists within-subject success count columns, Count column data.frame total number observations, uAlpha column containing mean pairwise correlation measured unitary alpha. , crange() can used place cbind() ","code":"dataCompiled1 ##   Class Difficulty success Count ## 1 First  Difficult       6    12 ## 2 First       Easy      11    12 ## 3 First   Moderate       9    12 ## 4  Last  Difficult       3    12 ## 5  Last       Easy      10    12 ## 6  Last   Moderate       8    12 w1Compiled <- anopa( {success; Count} ~ Class * Difficulty, dataCompiled1 ) dataCompiled2 ##     Status bpre bpost b1week b5week Count      uAlpha ## 1   Broken    5     5      6      5     8 -0.15204678 ## 2      New    2     3      4      2    10 -0.03463203 ## 3 Repaired    3     3      2      2     9 -0.10416667 w2Compiled <- anopa( {cbind(bpre, bpost, b1week, b5week); Count; uAlpha} ~ Status,                      dataCompiled2, WSFactors = \"Week(4)\") summary(w2Compiled) ##                      MS  df        F   pvalue correction    Fcorr pvalcorr ## Week           0.006472   3 0.221708 0.881375   1.030864 0.215070 0.886009 ## Status         0.174546   2 6.583566 0.001383   1.018673 6.462886 0.001560 ## Week:Status    0.005486   6 0.187927 0.980311   1.445036 0.130050 0.992591 ## Error(within)  0.029192 Inf                                                ## Error(between) 0.026512 Inf w2Compiledbis <- anopa( {crange(bpre, b5week); Count; uAlpha} ~ Status,                      dataCompiled2, WSFactors = \"Week(4)\") summary(w2Compiledbis) ##                      MS  df        F   pvalue correction    Fcorr pvalcorr ## Week           0.006472   3 0.221708 0.881375   1.030864 0.215070 0.886009 ## Status         0.174546   2 6.583566 0.001383   1.018673 6.462886 0.001560 ## Week:Status    0.005486   6 0.187927 0.980311   1.445036 0.130050 0.992591 ## Error(within)  0.029192 Inf                                                ## Error(between) 0.026512 Inf"},{"path":"https://dcousin3.github.io/ANOPA/articles/B-DataFormatsForProportions.html","id":"converting-between-formats","dir":"Articles","previous_headings":"","what":"Converting between formats","title":"Data formats for proportions","text":"entered anopa() structure, possible convert format using toWide(), toCompiled() toLong(). example: compiled format probably compact format, wide format explicit format (see subjects scores single line, one subject per line).","code":"toCompiled(w1) ##   Class Difficulty success Count ## 1 First  Difficult       6    12 ## 2 First       Easy      11    12 ## 3 First   Moderate       9    12 ## 4  Last  Difficult       3    12 ## 5  Last       Easy      10    12 ## 6  Last   Moderate       8    12 toCompiled(w2) ##     Status bpre bpost b1week b5week Count      uAlpha ## 1   Broken    5     5      6      5     8 -0.15204678 ## 2      New    2     3      4      2    10 -0.03463203 ## 3 Repaired    3     3      2      2     9 -0.10416667"},{"path":"https://dcousin3.github.io/ANOPA/articles/B-DataFormatsForProportions.html","id":"getting-the-example-data-frame","dir":"Articles","previous_headings":"","what":"Getting the example data frame","title":"Data formats for proportions","text":", used two examples. available package names twoWayExample minimalMxExample. first available compiled form, second wide form. converted data set formats using:","code":"w1 <- anopa( {success;total} ~ Class * Difficulty, twoWayExample) dataWide1     <- toWide(w1) dataCompiled1 <-toCompiled(w1) dataLong1     <- toLong(w1)  w2 <- anopa( cbind(bpre, bpost, b1week, b5week) ~ Status, minimalMxExample, WSFactors = \"Moment(4)\") dataWide2     <- toWide(w2) dataCompiled2 <-toCompiled(w2) dataLong2     <- toLong(w2)"},{"path":"https://dcousin3.github.io/ANOPA/articles/B-DataFormatsForProportions.html","id":"multiple-repeated-measure-factors","dir":"Articles","previous_headings":"","what":"Multiple repeated-measure factors","title":"Data formats for proportions","text":"One limitation regards repeated measures: possible guess name within-subject factors names columns. , soon one measurement, argument WSFactors must added. Suppose two-way within-subject design 2 x 3 levels. data set twoWayWithinExample 6 columns; first three factor , level 1, last three factor , level 2. Within triplet column, factor B goes 1 3. “fyi” message shown lets see variables interpreted. Take time verify order variables within cbind() match expected order anopa(). Note FYI messages can inhibited changing option know analyzing proportions ANOPA, refer Laurencelle & Cousineau (2023) ANOPA?.","code":"w3 <- anopa( cbind(r11,r12,r13,r21,r22,r23) ~ . ,               twoWayWithinExample,               WSFactors = c(\"B(3)\",\"A(2)\")              ) ## ANOPA::fyi: Here is how the within-subject variables are understood: ##  B A Variable ##  1 1      r11 ##  2 1      r12 ##  3 1      r13 ##  1 2      r21 ##  2 2      r22 ##  3 2      r23 toCompiled(w3) ##   r11 r12 r13 r21 r22 r23 Count     uAlpha ## 1  14   6   8  14  16  14    30 0.08223684 options(\"ANOPA.feedback\" = \"none\")"},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/articles/C-ConfidenceIntervals.html","id":"theory-behind-confidence-intervals-for-proportions","dir":"Articles","previous_headings":"","what":"Theory behind Confidence intervals for proportions","title":"Confidence intervals with proportions","text":"proportions, ANOPA based Anscombe transform . measure known theoretical standard error depends sample size nn: SEA(n)=1/4(n+1/2).SE_{}(n) = 1/\\sqrt{4(n+1/2)}. Consequently, groups’ sizes similar, homogeneity variances holds. , can decomposed total test statistic FF component cell design. thus get [+z0.5−γ/2×SEA(n),+z0.5+γ/2×SEA(n)]\\left[ + z_{0.5-\\gamma/2} \\times SE_{}(n), \\; + z_{0.5+\\gamma/2} \\times SE_{}(n) \\right] SEA(n)SE_{}(n) theoretical standard error based nn, γ\\gamma desired confidence level (often .95). use zz score ensues fact theoretical variance known. technique returns stand-alone confidence intervals, , intervals can used compare proportion fixed point. However, stand-alone intervals used compare one proportion another proportion (Cousineau et al., 2021). compare observed proportion another observed proportion, necessary adjust pair-wise differences (Baguley, 2012). achieved increasing wide intervals 2\\sqrt{2}. Also, repeated measure designs, correlation beneficial improve estimates. , interval wide can reduced correlation positive multiplying length 1−α1\\sqrt{1-\\alpha_1}, α1\\alpha_1 measure correlation matrix containing repeated measures (based unitary alpha measure). Finally, returns confidence intervals transformed scores. However, used plot, typically convenient plot proportions (ranging 0 1) rather Anscombe-scores (ranging 0 π/2≈\\pi/2 \\approx 1.57). Thus, possible rescale vertical axis using inverse Anscombe transform shown proportions. .","code":""},{"path":"https://dcousin3.github.io/ANOPA/articles/C-ConfidenceIntervals.html","id":"complicated","dir":"Articles","previous_headings":"","what":"Complicated?","title":"Confidence intervals with proportions","text":"Well, really: Figure 1. proportions function class Difficulty. Error bars show difference-adjusted 95% confidence intervals. analyses summary(w) suggests factor Difficulty significant effect, may select factors plotting, e.g., Figure 2. proportions function Difficulty . Error bars show difference-adjusted 95% confidence intervals. case ggplot2 figure, can customize . example, Figure 3. Figure 2 visual improvements. can see plot, Difficulty significant, different conditions Easy vs. Difficult. go.","code":"library(ANOPA) w <- anopa( {success;total} ~ Class * Difficulty, twoWayExample) anopaPlot(w) anopaPlot(w, ~ Difficulty ) library(ggplot2) anopaPlot(w, ~ Difficulty) +              theme_bw() +  # change theme             scale_x_discrete(limits = c(\"Easy\", \"Moderate\", \"Difficult\")) #change order"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/articles/F-TestingTypeIError.html","id":"simulation-with-one-between-factor","dir":"Articles","previous_headings":"Simulations with a single factor","what":"Simulation with one between factor","title":"Testing type-I error rates","text":"","code":"frm      <- s ~ grp         # the formula BSDesign <- list(grp = c(\"ctrl\",\"plcbo\")) #one factor, two groups thePs    <- c(0.3, 0.3)     # the true proportions, equal  # test type-I error rate when no effect as is the case for factor 2 set.seed(41) res <- c() for (i in 1:nsim) {     smp <- GRP( thePs, theN, BSDesign )     w   <- anopa(frm, smp[,2:3] )     res <- c(res, if(summarize(w)[1,4]<.05) 1 else 0) } typeI <- mean(res) cat( \"Design B,     testing B: \", typeI, \"\\n\")  # tolerance is large as the number of simulations is small expect_equal( typeI, .05, tolerance = 0.035)"},{"path":"https://dcousin3.github.io/ANOPA/articles/F-TestingTypeIError.html","id":"simulation-with-one-within-factor","dir":"Articles","previous_headings":"Simulations with a single factor","what":"Simulation with one within factor","title":"Testing type-I error rates","text":"","code":"frm      <- cbind(s.early, s.middle, s.late) ~ . WSDesign <- list(moment = c(\"early\",\"middle\",\"late\")) thePs    <- c(0.3, 0.3, 0.3)  # test type-I error rate when no effect as is the case for factor 2 set.seed(42) res <- c() for (i in 1:nsim) {     smp <- GRP( thePs, theN, NULL, WSDesign )     w   <- anopa(frm, smp[,2:4] , WSFactors = \"M(3)\" )     res <- c(res, if(summarize(w)[1,4]<.05) 1 else 0) } typeI <- mean(res) cat( \"Design W,     testing W: \", typeI, \"\\n\")  # tolerance is large as the number of simulations is small expect_equal( typeI, .05, tolerance = 0.035)"},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/articles/F-TestingTypeIError.html","id":"simulation-with-two-factors-between-design","dir":"Articles","previous_headings":"Simulations with two factors","what":"Simulation with two factors, between design","title":"Testing type-I error rates","text":"","code":"frm      <- s ~ grp * eta WSDesign <- list() BSDesign <- list(eta = c(\"repue\",\"ajun\"), grp = c(\"early\",\"middle\",\"late\")) thePs    <- c(0.3, 0.3, 0.5, 0.5, 0.7, 0.7)  # test type-I error rate when no effect as is the case for factor 2 set.seed(41) res <- c() for (i in 1:nsim) {     smp <- GRP( thePs, theN, BSDesign )     w   <- anopa(frm, smp )     res <- c(res, if(summarize(w)[2,4]<.05) 1 else 0) } typeI <- mean(res) cat( \"Design BxB,   testing B: \", typeI, \"\\n\")  # tolerance is large as the number of simulations is small expect_equal( typeI, .05, tolerance = 0.035)"},{"path":"https://dcousin3.github.io/ANOPA/articles/F-TestingTypeIError.html","id":"simulation-with-two-factors-within-design","dir":"Articles","previous_headings":"Simulations with two factors","what":"Simulation with two factors, within design","title":"Testing type-I error rates","text":"","code":"frm      <- cbind(s.repue.early, s.ajun.early,                    s.repue.middle, s.ajun.middle,                    s.repue.late, s.ajun.late) ~ . BSDesign <- list() WSDesign <- list(eta = c(\"repue\",\"ajun\"), moment = c(\"early\",\"middle\",\"late\")) thePs    <- c(0.3, 0.3, 0.5, 0.5, 0.7, 0.7) # thePs    <- c(0.3, 0.7, 0.3, 0.7, 0.3, 0.7) # or no effect on factor 1  # test type-I error rate when no effect as is the case for factor 2 set.seed(41) res <- c() for (i in 1:nsim) {     smp <- GRP( thePs, theN, NULL, WSDesign )     w   <- anopa(frm, smp, WSFactors = c(\"e(2)\", \"m(3)\") )     res <- c(res, if(summarize(w)[2,4]<.05) 1 else 0) } typeI <- mean(res) cat( \"Design WxW,   testing W: \", typeI, \"\\n\")  # tolerance is large as the number of simulations is small expect_equal( typeI, .05, tolerance = 0.035)"},{"path":"https://dcousin3.github.io/ANOPA/articles/F-TestingTypeIError.html","id":"simulation-with-two-factors-mixed-design","dir":"Articles","previous_headings":"Simulations with two factors","what":"Simulation with two factors, mixed design","title":"Testing type-I error rates","text":"","code":"frm      <- cbind(s.early, s.middle, s.late) ~ grp BSDesign <- list(grp = c(\"ctrl\",\"plcbo\")) WSDesign <- list(moment = c(\"early\",\"middle\",\"late\")) thePs    <- c(0.3, 0.3, 0.5, 0.5, 0.7, 0.7) # thePs    <- c(0.3, 0.7, 0.3, 0.7, 0.3, 0.7) # or no effect on factor 1  # test type-I error rate when no effect as is the case for factor 2 set.seed(41) res <- c() for (i in 1:nsim) {     smp <- GRP( thePs, theN, BSDesign, WSDesign )     w   <- anopa(frm, smp[,2:5] , WSFactors = \"M(3)\")     res <- c(res, if(summarize(w)[2,4]<.05) 1 else 0) } typeI <- mean(res) cat( \"Design WxB,   testing B: \", typeI, \"\\n\")  # tolerance is large as the number of simulations is small expect_equal( typeI, .05, tolerance = 0.035)"},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/articles/F-TestingTypeIError.html","id":"simulation-with-three-factors-all-between-design","dir":"Articles","previous_headings":"Simulations with three factors","what":"Simulation with three factors, all between design","title":"Testing type-I error rates","text":"","code":"frm      <- s ~ grp * eta * a BSDesign <- list(eta = c(\"repue\",\"ajun\"),                   grp = c(\"early\",\"middle\",\"late\"), a = c(\"1\",\"2\",\"3\",\"4\")) thePs    <- rep(0.3, 24)  # test type-I error rate when no effect as is the case for factor 2 set.seed(41) res <- c() for (i in 1:nsim) {     smp <- GRP( thePs, theN, BSDesign )     w   <- anopa(frm, smp )     res <- c(res, if(summarize(w)[2,4]<.05) 1 else 0) } typeI <- mean(res) cat( \"Design BxBxB, testing B: \", typeI, \"\\n\")  # tolerance is large as the number of simulations is small expect_equal( typeI, .05, tolerance = 0.035)"},{"path":"https://dcousin3.github.io/ANOPA/articles/F-TestingTypeIError.html","id":"simulation-with-three-factors-within-design","dir":"Articles","previous_headings":"Simulations with three factors","what":"Simulation with three factors, within design","title":"Testing type-I error rates","text":"","code":"frm      <- cbind(s.repue.early.1,  s.ajun.early.1,  s.repue.middle.1,             s.ajun.middle.1, s.repue.late.1,   s.ajun.late.1,   s.repue.early.2,              s.ajun.early.2,  s.repue.middle.2, s.ajun.middle.2, s.repue.late.2,             s.ajun.late.2,   s.repue.early.3,  s.ajun.early.3,  s.repue.middle.3,             s.ajun.middle.3, s.repue.late.3,   s.ajun.late.3,   s.repue.early.4,              s.ajun.early.4,  s.repue.middle.4, s.ajun.middle.4, s.repue.late.4,             s.ajun.late.4 ) ~ . WSDesign <- list(eta = c(\"repue\",\"ajun\"), grp = c(\"early\",\"middle\",\"late\"), a = c(\"1\",\"2\",\"3\",\"4\")) thePs    <- rep(0.3, 24)  # test type-I error rate when no effect as is the case for factor 2 set.seed(43) res <- c() for (i in 1:nsim) {     smp <- GRP( thePs, theN, NULL, WSDesign )     w   <- anopa(frm, smp, WSFactors = c(\"e(2)\",\"g(3)\", \"a(4)\") )     res <- c(res, if(summarize(w)[2,4]<.05) 1 else 0) } typeI <- mean(res) cat( \"Design WxWxW, testing W: \", typeI, \"\\n\")  # tolerance is large as the number of simulations is small expect_equal( typeI, .05, tolerance = 0.035)"},{"path":"https://dcousin3.github.io/ANOPA/articles/F-TestingTypeIError.html","id":"simulation-with-three-factors-mixed-design-testing-within","dir":"Articles","previous_headings":"Simulations with three factors","what":"Simulation with three factors, mixed design, testing within","title":"Testing type-I error rates","text":"","code":"frm      <- cbind(s.repue.early,  s.ajun.early,  s.repue.middle, s.ajun.middle, s.repue.late,  s.ajun.late ) ~ a BSDesign <- list( a = c(\"1\",\"2\",\"3\",\"4\") ) WSDesign <- list(eta = c(\"repue\",\"ajun\"), grp = c(\"early\",\"middle\",\"late\") ) thePs    <- rep(0.3, 24)  # test type-I error rate when no effect as is the case for factor 2 set.seed(43) res <- c() for (i in 1:nsim) {     smp <- GRP( thePs, theN, BSDesign, WSDesign )     w   <- anopa(frm, smp, WSFactors = c(\"e(2)\",\"g(3)\") )     res <- c(res, if(summarize(w)[1,4]<.05) 1 else 0) } typeI <- mean(res) cat( \"Design BxWxW, testing W: \", typeI, \"\\n\")  # tolerance is large as the number of simulations is small expect_equal( typeI, .05, tolerance = 0.035)"},{"path":"https://dcousin3.github.io/ANOPA/articles/F-TestingTypeIError.html","id":"simulation-with-three-factors-mixed-design-testing-between","dir":"Articles","previous_headings":"Simulations with three factors","what":"Simulation with three factors, mixed design, testing between","title":"Testing type-I error rates","text":"","code":"frm      <- cbind(s.repue.early,  s.ajun.early,  s.repue.middle, s.ajun.middle, s.repue.late,  s.ajun.late ) ~ a BSDesign <- list( a = c(\"1\",\"2\",\"3\",\"4\") ) WSDesign <- list(eta = c(\"repue\",\"ajun\"), grp = c(\"early\",\"middle\",\"late\") ) thePs    <- rep(0.3, 24)  # test type-I error rate when no effect as is the case for factor 2 set.seed(42) res <- c() for (i in 1:nsim) {     smp <- GRP( thePs, theN, BSDesign, WSDesign )     w   <- anopa(frm, smp, WSFactors = c(\"e(2)\",\"g(3)\") )     res <- c(res, if(summarize(w)[3,4]<.05) 1 else 0) } typeI <- mean(res) cat( \"Design BxWxW, testing B: \", typeI, \"\\n\")  # tolerance is large as the number of simulations is small expect_equal( typeI, .05, tolerance = 0.035)"},{"path":"https://dcousin3.github.io/ANOPA/articles/F-TestingTypeIError.html","id":"the-end","dir":"Articles","previous_headings":"","what":"The end","title":"Testing type-I error rates","text":"gain confidence, increase number simulations markedly reduce tolerance around .05. decent Monte Carlo simulations based 50,000 simulations (20!) tolerance .001. leaving, let’s restore warnings messages:","code":"options(\"ANOPA.feedback\" = 'all')"},{"path":"https://dcousin3.github.io/ANOPA/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Denis Cousineau. Author, contributor, maintainer. Louis Laurencelle. Author, contributor.","code":""},{"path":"https://dcousin3.github.io/ANOPA/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Laurencelle L Cousineau D (2023) Analysis proportions using arcsine transform experimental design. Frontiers Psychology, 13:1045436. doi: 10.3389/fpsyg.2022.1045436","code":"@Article{,   title = {Analysis of proportions using arcsine transform with any experimental design},   author = {Louis Laurencelle and Denis Cousineau},   journal = {Frontiers in Psychology},   year = {2023},   volume = {13},   issue = {1045436},   pages = {1--12},   url = {https://dcousin3.github.io/ANOPA/},   doi = {10.3389/fpsyg.2022.1045436}, }"},{"path":"https://dcousin3.github.io/ANOPA/index.html","id":"anopa-analysis-of-proportions-using-anscombe-transform","dir":"","previous_headings":"","what":"Analyses of Proportions using Anscombe Transform","title":"Analyses of Proportions using Anscombe Transform","text":"library ANOPA provides easy--use tools analyze proportions . , can examine proportions significantly different (show effect). case one factor, can also test interaction(s) significant. can also test simple effects (.k.. expected marginal analysis), well post-hoc tests (using Tukey’s Honestly Significant Difference test HSD). Finally, can assess differences based orthogonal contrasts. can consult Laurencelle & Cousineau (2023) details. ANOPA also comes () tools make plot proportions along 95% confidence intervals [intervals adjusted pair- wise comparisons; Cousineau, Goulet, & Harding (2021)]; (b) tools compute statistical power given priori expected proportions sample size reach certain statistical power; (c) generate random proportions wish perform Monte Carlo simulations proportions. sum, everything need analyse proportions! main function anopa() returns omnibus analysis proportions factors given. example, data frame ArticleExample2 contains column called s number successes per group stored, column called n group sizes stored, following performs analysis proportions function groups based columns SES MofDiagnostic: results suggest (consult first three columns), main effect factor SES (F(2, inf) = 6.395, p = .002). plot proportions can obtained easily  just main effect figure  interaction significant, simple effects can analyzed expected marginal frequencies e <- emProportions(w, ~ SES | MofDiagnostic ). Follow-analyses include contrasts examinations contrastProportions(); finally, post-hoc pairwise comparisons can obtained posthocProportions(). Prior running experiment, might consider statistical power planning proportions using anopaPower2N() anopaN2Power() long can anticipate expected proportions. convenient effect size, f-square eta-square can obtained anopaProp2fsq(). Finally, toCompiled(), toLong() toWide() can used present proportion formats.","code":"w <- anopa( {s; n} ~ SES * MofDiagnostic, ArticleExample2 ) summary(w) ##                         MS  df        F   pvalue correction    Fcorr pvalcorr ## SES               0.022242   2 6.394845 0.001670   1.004652 6.365237 0.001720 ## MofDiagnostic     0.001742   1 0.500966 0.479076   1.002248 0.499842 0.479569 ## SES:MofDiagnostic 0.007443   2 2.140035 0.117651   1.040875 2.055997 0.127965 ## Error(between)    0.003478 Inf anopaPlot(w) anopaPlot(w, ~ SES)"},{"path":"https://dcousin3.github.io/ANOPA/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Analyses of Proportions using Anscombe Transform","text":"official CRAN version can installed development version 0.2.2 can accessed GitHub: Note package ANOPA named using UPPERCASE letters whereas main function anopa() written using lowercase letters. library loaded ","code":"install.packages(\"ANOPA\") library(ANOPA) devtools::install_github(\"dcousin3/ANOPA\") library(ANOPA) library(ANOPA)"},{"path":"https://dcousin3.github.io/ANOPA/index.html","id":"in-sum","dir":"","previous_headings":"","what":"In sum","title":"Analyses of Proportions using Anscombe Transform","text":"seen, library ANOPA makes easy analyze proportions using general vocabulary found ANOVAs. complete documentation available site. general introduction ANOPA framework underlying library can found Laurencelle & Cousineau (2023).","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/A.html","id":null,"dir":"Reference","previous_headings":"","what":"transformation functions — A","title":"transformation functions — A","text":"transformation functions '()' performs Anscombe transformation pair {number success; number trials} = {s; n} (symbol \";\" read \"\". function 'varA()' returns theoretical variance pair {s; n}. functions central ANOPA lc23ANOPA. originally proposed z35ANOPA formalized a48ANOPA.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/A.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"transformation functions — A","text":"","code":"A(s, n)  varA(s, n)  Atrans(v)  SE.Atrans(v)  var.Atrans(v)  CI.Atrans(v, gamma)  prop(v)  CI.prop(v, gamma)"},{"path":"https://dcousin3.github.io/ANOPA/reference/A.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"transformation functions — A","text":"s number success; n number trials. v vector 0s 1s. gamma confidence level, default .95 omitted.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/A.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"transformation functions — A","text":"() returns score 0 1.57 s zero results (0,n) tending zero number trials large, maximum occurs s equals n large, example (1000,1000) = 1.55. midpoint always 0.786 irrespective number trials (0.5 * n, n) = 0.786. function varA() returns theoretical variance Anscombe transformed score. exact n gets large, overestimate variance n small. Therefore, test based transform either exact conservative.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/A.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"transformation functions — A","text":"functions () varA() take input two integers, s number success n number observations. functions Atrans(), SE.Atrans(), var.Atrans(), CI.Atrans(), prop() CI.prop() take input single vector v 0s 1s number success number observations derived.","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/A.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"transformation functions — A","text":"","code":"# The transformations from number of 1s and total number of observations: A(5, 10) #> [1] 0.7853982   varA(5, 10) #> [1] 0.02380952   # Same with a vector of observations: Atrans( c(1,1,1,1,1,0,0,0,0,0) ) #> [1] 0.7853982   var.Atrans( c(1,1,1,1,1,0,0,0,0,0) ) #> [1] 0.02380952"},{"path":"https://dcousin3.github.io/ANOPA/reference/ANOPA-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ANOPA: Analyses of Proportions using Anscombe Transform — ANOPA-package","title":"ANOPA: Analyses of Proportions using Anscombe Transform — ANOPA-package","text":"'ANOPA' library perform proportion analyses. based F statistics (first developed Fisher). statistics fully additive can decomposed main effects interaction effects, simple effects decomposition significant interaction, contrasts, etc. present library performs analyses also can used plan statistical power analysis proportions, obtain plots various effects, etc. aims replicating commonly-used ANOVA commands using package easy. data supplied ANOPA can three formats: () long format, (ii) wide format, (iii) compiled format, (iv) raw format. Check 'anopa' commands precision (follow, assume compiled format proportions given column name 'Freq') main function w <- anopa(formula, data) formula formula giving factors, e.g., \"Freq ~ * B\". details underlying math, see lc23;textualANOPA. omnibus analysis may followed simple effects contrasts analyses: emProportions(w, formula) contrast(w, listOfContrasts) usual, output can obtained print(w) #implicite summary(w) # summarize(w) G statistics table explain(w) # human-readable output Data format can converted format toLong(w) toWide(w) toCompiled(w) # format used input anopa package includes additional, helper, functions: anopaPower2N() compute sample size given effect size; anopaN2Power() compute statistical power given sample size; anopaPropTofsq() compute effect size; anopaPlot() obtain plot proportions error bars; GRP() generate random proportions given design. example datasets, described article: ArringtonEtAl2002 illustrates 3 x 2 x 4 design; ArticleExample1 illustrates 4-way design; ArticleExample2 illustrates 2 x 3  design; ArticleExample3 illustrates (4) within-subject design; functions uses following options: ANOPA.feedback 'design', 'warnings', 'summary', '' 'none'; ANOPA.zeros    handled zero trials avoid 0 divided 0 error; ANOPA.digits   number digits displayed summary table.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/ANOPA-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ANOPA: Analyses of Proportions using Anscombe Transform — ANOPA-package","text":"ANOPA library analyses proportions using Anscombe transform","code":""},{"path":[]},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/ANOPA-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ANOPA: Analyses of Proportions using Anscombe Transform — ANOPA-package","text":"Maintainer: Denis Cousineau denis.cousineau@uottawa.ca [contributor] Authors: Louis Laurencelle louis.laurencelle@gmail.com [contributor]","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/anopaN2Power.html","id":null,"dir":"Reference","previous_headings":"","what":"Computing power within the ANOPA. — anopaN2Power","title":"Computing power within the ANOPA. — anopaN2Power","text":"function 'anopaN2Power()' performs analysis statistical power according 'ANOPA' framework. See lc23b;textualANOPA . 'anopaPower2N()' computes sample size reach given power. Finally, 'anopaProp2fsq()' computes f^2 effect size set proportions.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/anopaN2Power.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computing power within the ANOPA. — anopaN2Power","text":"","code":"anopaPower2N(power, P, f2, alpha)  anopaN2Power(N, P, f2, alpha)  anopaProp2fsq(props, ns, unitaryAlpha, method=\"approximation\")"},{"path":"https://dcousin3.github.io/ANOPA/reference/anopaN2Power.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computing power within the ANOPA. — anopaN2Power","text":"N sample size; P number groups; f2 effect size Cohen's $f^2$; alpha (default omitted .05) decision threshold. power target power attain; ns sample size per group; props set expected proportions (0 1) number success per group. method computing effect size $f^2$ 'approximation' 'exact' . unitaryAlpha within-subject design, measure correlation across measurements.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/anopaN2Power.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computing power within the ANOPA. — anopaN2Power","text":"anopaPower2N() returns sample size reach given power level. anopaN2Power() returns statistical power given sample size. anopaProp2fsq() returns $f^2$ effect size set proportions sample sizes.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/anopaN2Power.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computing power within the ANOPA. — anopaN2Power","text":"Note anopaProp2fsq(), expected effect size $f^2$ depends weakly sample sizes. Indeed, Anscombe transform can reach extreme scores sample sizes larger, influencing expected effect size.","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/anopaN2Power.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computing power within the ANOPA. — anopaN2Power","text":"","code":"# 1- Example of the article: # with expected frequences .34 to .16, assuming as a first guess groups of 25 observations: f2 <- anopaProp2fsq( c( 0.32, 0.64, 0.40, 0.16), c(25,25,25,25) ); f2 #> [1] 0.1280757 # f-square is 0.128.  # f-square can be converted to eta-square with eta2 <- f2 / (1 + f2)   # With a total sample of 97 observations over four groups, # statistical power is quite satisfactory (85%). anopaN2Power(97, 4, f2) #> [1] 0.8538199  # 2- Power planning. # Suppose we plan a four-classification design with expected proportions of: pred <- c(.35, .25, .25, .15) # P is the number of classes (here 4) P <- length(pred) # We compute the predicted f2 as per Eq. 5 f2 <- 2 * sum(pred * log(P * pred) ) # the result, 0.0822, is a moderate effect size.  # Finally, aiming for a power of 80%, we run anopaPower2N(0.80, P, f2) #> [1] 132.501 # to find that a little more than 132 participants are enough."},{"path":"https://dcousin3.github.io/ANOPA/reference/anopa_asn_trans1.html","id":null,"dir":"Reference","previous_headings":"","what":"anopaPlot: Easy plotting of proportions. — anopa_asn_trans1","title":"anopaPlot: Easy plotting of proportions. — anopa_asn_trans1","text":"function 'anopaPlot()' performs plot proportions designs 4 factors according 'ANOPA' framework. See lc23;textualANOPA . plot realized using 'superb' library; see cgh21;textualANOPA. uses arc-sine transformation '()'.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/anopa_asn_trans1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"anopaPlot: Easy plotting of proportions. — anopa_asn_trans1","text":"","code":"anopaPlot(w, formula = NULL, confidenceLevel = .95, allowImputing = FALSE,      showPlotOnly = TRUE, plotLayout = \"line\",       errorbarParams  = list( width =0.85, linewidth=0.75 ), ...)"},{"path":"https://dcousin3.github.io/ANOPA/reference/anopa_asn_trans1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"anopaPlot: Easy plotting of proportions. — anopa_asn_trans1","text":"w ANOPA object obtained anopa(); formula (optional) Use formula plot just specific terms omnibus test. example, analysis stored w factors , B C, anopaPlot(w, ~ * B) plot factors B. confidenceLevel Provide confidence level confidence intervals (default 0.95, .e., 95%). allowImputing (default FALSE) cells observations, can imputed? imputed, option \"ANOPA.zeros\" used determine many additional observations add, many successes. example, option (default) c(0.05, 1), 20 cases added, one success (respecting .05 target). Keep mind imputations never studies regards proportions mindful default optin never tested validated. showPlotOnly (optional, default True) shows plot else shows numbers needed make plot . plotLayout (optional; default \"line\") plot proportions; see superb layouts (e.g., \"line\"). errorbarParams (optional; default list( width =0.5, linewidth=0.75 ) ) list attributes used plot error bars. See superb . ... directives sent superb(), typically 'plotLayout', 'errorbarParams', etc.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/anopa_asn_trans1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"anopaPlot: Easy plotting of proportions. — anopa_asn_trans1","text":"ggplot2 object given proportions.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/anopa_asn_trans1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"anopaPlot: Easy plotting of proportions. — anopa_asn_trans1","text":"plot shows proportions vertical axis function factors (first horizontal axis, second legend; third even fourth factors present, distinct rows columns). also shows 95% confidence intervals proportions, adjusted -cells comparisons. confidence intervals based z distribution, adequate large samples c90,ll90ANOPA. \"stand-alone\" confidence interval adjusted -cell comparisons using superb framework cgh21ANOPA. See vignette DataFormatsForProportions data formats write formula. See vignette ConfidenceIntervals details adjustment purpose.","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/anopa_asn_trans1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"anopaPlot: Easy plotting of proportions. — anopa_asn_trans1","text":"","code":"#  # The Arrington Et Al., 2002, data on fishes' stomach ArringtonEtAl2002 #>                 Location    Trophism      Diel    s    n #> 1                 Africa Detritivore   Diurnal   16  217 #> 2                 Africa Invertivore   Diurnal   76  498 #> 3                 Africa Invertivore Nocturnal   55  430 #> 4                 Africa    Omnivore   Diurnal    2   87 #> 5                 Africa   Piscivore   Diurnal  673  989 #> 6                 Africa   Piscivore Nocturnal  221  525 #> 7  Central/South America Detritivore   Diurnal   68 1589 #> 8  Central/South America Detritivore Nocturnal    9  318 #> 9  Central/South America Invertivore   Diurnal  706 7452 #> 10 Central/South America Invertivore Nocturnal  486 2101 #> 11 Central/South America    Omnivore   Diurnal  293 6496 #> 12 Central/South America    Omnivore Nocturnal   82  203 #> 13 Central/South America   Piscivore   Diurnal 1275 5226 #> 14 Central/South America   Piscivore Nocturnal  109  824 #> 15         North America Detritivore   Diurnal  142 1741 #> 16         North America Invertivore   Diurnal  525 3368 #> 17         North America Invertivore Nocturnal  231 1539 #> 18         North America    Omnivore   Diurnal  210 1843 #> 19         North America    Omnivore Nocturnal    7   38 #> 20         North America   Piscivore   Diurnal  536 1289 #> 21         North America   Piscivore Nocturnal   19  102  # This examine the omnibus analysis, that is, a 3 x 2 x 4 ANOPA: w <- anopa( {s;n} ~ Location * Trophism * Diel, ArringtonEtAl2002)  #> ANOPA::fyi(1): Combination of cells missing. Adding:  #>       Location    Trophism      Diel s n #>         Africa Detritivore Nocturnal 0 0 #>         Africa    Omnivore Nocturnal 0 0 #>  North America Detritivore Nocturnal 0 0 #> Warning: ANOPA::warning(1): Some cells have zero over zero data. Imputing...  # Once processed into w, we can ask for a standard plot anopaPlot(w)   # As you may notice, there are points missing because the data have # three missing cells. The litterature is not clear what should be  # done with missing cells. In this package, we propose to impute # the missing cells based on the option `getOption(\"ANOPA.zeros\")`. # Consider this option with care.   anopaPlot(w, allowImputing = TRUE) #> Warning: ANOPA::warning(201): Cell Africa Detritivore Nocturnal missing in data. Imputing... #> Warning: ANOPA::warning(201): Cell Africa Omnivore Nocturnal missing in data. Imputing... #> Warning: ANOPA::warning(201): Cell North America Detritivore Nocturnal missing in data. Imputing...   # We can place the factor `Diel` on the x-axis (first): anopaPlot(w, ~ Diel * Trophism * Location )   # Change the style for a plot with bars instead of lines anopaPlot(w, plotLayout = \"bar\")   # Changing the error bar style anopaPlot(w, plotLayout = \"bar\", errorbarParams = list( width =0.1, linewidth=0.1 ) )   # Illustrating the main effect of Location (not interacting with other factors) # and the interaction Diel * Trophism separately anopaPlot(w, ~ Location )   anopaPlot(w, ~ Diel * Trophism )    # All these plots are ggplot2 so they can be followed with additional directives, e.g. library(ggplot2) anopaPlot(w, ~ Location) + ylim(0.0, 1.0) + theme_classic() #> Scale for y is already present. #> Adding another scale for y, which will replace the existing scale.  anopaPlot(w, ~ Diel * Trophism) + ylim(0.0, 1.0) + theme_classic() #> Scale for y is already present. #> Adding another scale for y, which will replace the existing scale.   # etc. Any ggplot2 directive can be added to customize the plot to your liking. # See the vignette `ArringtonExample`."},{"path":"https://dcousin3.github.io/ANOPA/reference/ArringtonEtAl2002.html","id":null,"dir":"Reference","previous_headings":"","what":"Arrington et al. (2002) dataset — ArringtonEtAl2002","title":"Arrington et al. (2002) dataset — ArringtonEtAl2002","text":"data, taken a02;textualANOPA, dataset examining distribution fishes empty stomachs, classified three factors: 'Collection location' (3 levels: Africa, Central/South America, North America), 'Diel feeding behavior' (2 levels: diurnal, nocturnal), 'Trophic category' (4 levels: Detrivore, Invertivore, Omnivore, Piscivore). therefore 3 × 2 × 4 design 24 cells. original data set also contains Order, Family Species observed fishes can obtained https://figshare.com/collections/HOW_OFTEN_DO_FISHES_RUN_ON_EMPTY_/3297635 commented wh11;textualANOPA.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/ArringtonEtAl2002.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arrington et al. (2002) dataset — ArringtonEtAl2002","text":"","code":"ArringtonEtAl2002"},{"path":"https://dcousin3.github.io/ANOPA/reference/ArringtonEtAl2002.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Arrington et al. (2002) dataset — ArringtonEtAl2002","text":"data frame.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/ArringtonEtAl2002.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Arrington et al. (2002) dataset — ArringtonEtAl2002","text":"doi:10.1890/0012-9658(2002)083[2145:HODFRO]2.0.CO;2","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/ArringtonEtAl2002.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Arrington et al. (2002) dataset — ArringtonEtAl2002","text":"","code":"# see the dataset ArringtonEtAl2002 #>                 Location    Trophism      Diel    s    n #> 1                 Africa Detritivore   Diurnal   16  217 #> 2                 Africa Invertivore   Diurnal   76  498 #> 3                 Africa Invertivore Nocturnal   55  430 #> 4                 Africa    Omnivore   Diurnal    2   87 #> 5                 Africa   Piscivore   Diurnal  673  989 #> 6                 Africa   Piscivore Nocturnal  221  525 #> 7  Central/South America Detritivore   Diurnal   68 1589 #> 8  Central/South America Detritivore Nocturnal    9  318 #> 9  Central/South America Invertivore   Diurnal  706 7452 #> 10 Central/South America Invertivore Nocturnal  486 2101 #> 11 Central/South America    Omnivore   Diurnal  293 6496 #> 12 Central/South America    Omnivore Nocturnal   82  203 #> 13 Central/South America   Piscivore   Diurnal 1275 5226 #> 14 Central/South America   Piscivore Nocturnal  109  824 #> 15         North America Detritivore   Diurnal  142 1741 #> 16         North America Invertivore   Diurnal  525 3368 #> 17         North America Invertivore Nocturnal  231 1539 #> 18         North America    Omnivore   Diurnal  210 1843 #> 19         North America    Omnivore Nocturnal    7   38 #> 20         North America   Piscivore   Diurnal  536 1289 #> 21         North America   Piscivore Nocturnal   19  102  # The columns s and n indicate the number of fishes with # empty stomachs (the \"success\") and the total number # of fishes observed, respectively. Thus s/n is the proportion.  # run the ANOPA analysis w <- anopa( {s; n} ~  Location * Diel * Trophism, ArringtonEtAl2002) #> ANOPA::fyi(1): Combination of cells missing. Adding:  #>       Location      Diel    Trophism s n #>         Africa Nocturnal Detritivore 0 0 #>         Africa Nocturnal    Omnivore 0 0 #>  North America Nocturnal Detritivore 0 0 #> Warning: ANOPA::warning(1): Some cells have zero over zero data. Imputing...  # make a plot with all the factors anopaPlot(w)   # ... or with a subset of factors, with anopaPlot(w, ~ Location * Trophism)   # Because of the three-way interaction, extract simple effects for each Diel e <- emProportions( w, {s;n} ~ Location * Trophism | Diel  )   # As the two-way simple interaction for Nocturnal * Diel is close to significant,  # we extract the second-order simple effects for each Diel and each Location e <- emProportions(w, {s;n} ~ Trophism | Location * Diel  )  # As seen, the Trophism is significant for Noctural fishes of  # Central/South America."},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample1.html","id":null,"dir":"Reference","previous_headings":"","what":"ArticleExample1 — ArticleExample1","title":"ArticleExample1 — ArticleExample1","text":"data first example reported lc23ANOPA. shows fictitious data regards proportion incubation function distracting task. design -subject design 4 groups.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ArticleExample1 — ArticleExample1","text":"","code":"ArticleExample1"},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"ArticleExample1 — ArticleExample1","text":"object class data.frame.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample1.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"ArticleExample1 — ArticleExample1","text":"doi:10.20982/tqmp.19.2.p173","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ArticleExample1 — ArticleExample1","text":"","code":"library(ANOPA)  # the ArticleExample1 data shows an effect of the type of distracting task  ArticleExample1 #>   DistractingTask nSuccess nParticipants #> 1      Crosswords       10            30 #> 2          Sudoku       14            22 #> 3          Chants        7            18 #> 4          Breath        5            27  # We perform an anopa on this dataset w <- anopa( {nSuccess; nParticipants} ~ DistractingTask, ArticleExample1)  # We finish with post-hoc Tukey test e <- posthocProportions( w ) #> Not yet programmed...  # a small plot is *always* a good idea anopaPlot(w)"},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample2.html","id":null,"dir":"Reference","previous_headings":"","what":"ArticleExample2 — ArticleExample2","title":"ArticleExample2 — ArticleExample2","text":"data second example reported lc23ANOPA. shows fictitious data regards proportion graduation persons dyslexia function moment diagnostic (early late) socoi-economic status (SES). design -subject design 2 x 3 = 6 groups.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ArticleExample2 — ArticleExample2","text":"","code":"ArticleExample2"},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"ArticleExample2 — ArticleExample2","text":"object class data.frame.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"ArticleExample2 — ArticleExample2","text":"doi:10.20982/tqmp.19.2.p173","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ArticleExample2 — ArticleExample2","text":"","code":"library(ANOPA)  # the ArticleExample2 data shows an effect on the success to graduate as a function of # socioeconomic status and moment of diagnostic: ArticleExample2 #>   MofDiagnostic    SES  s  n #> 1         Early    Low 75 89 #> 2         Early Middle 62 77 #> 3         Early   High 40 52 #> 4          Late    Low 84 92 #> 5          Late Middle 52 72 #> 6          Late   High 42 63  # perform an anopa on this dataset w <- anopa( {s;n} ~ MofDiagnostic * SES, ArticleExample2)  # a small plot is *always* a good idea anopaPlot(w)  # here the plot is only for the main effect of SES. anopaPlot(w, ~ SES)"},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample3.html","id":null,"dir":"Reference","previous_headings":"","what":"ArticleExample3 — ArticleExample3","title":"ArticleExample3 — ArticleExample3","text":"data third example reported lc23ANOPA. shows fictitious data regards proportion patients suffering delirium tremens function drug administered (cBau, eaPoe, R&V, Placebo). design within-subject design 4 measurements (order administration randomized).","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ArticleExample3 — ArticleExample3","text":"","code":"ArticleExample3"},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample3.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"ArticleExample3 — ArticleExample3","text":"object class data.frame.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample3.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"ArticleExample3 — ArticleExample3","text":"doi:10.20982/tqmp.19.2.p173","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/ArticleExample3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ArticleExample3 — ArticleExample3","text":"","code":"library(ANOPA)  # the ArticleExample3 data shows an effect of the drug administered on the  # proportion of participants who had an episode of delirium tremens  ArticleExample3 #>    cBau eaPoe RnV Placebo #> 1     1     0   0       0 #> 2     1     1   1       1 #> 3     0     0   0       0 #> 4     1     1   0       0 #> 5     0     0   0       0 #> 6     0     0   0       0 #> 7     1     0   1       1 #> 8     0     0   0       0 #> 9     1     1   0       1 #> 10    0     0   0       0 #> 11    1     0   0       0 #> 12    1     1   1       1 #> 13    0     0   0       0 #> 14    0     0   0       0 #> 15    1     0   0       0 #> 16    0     0   1       1 #> 17    0     0   0       0 #> 18    0     0   0       1 #> 19    1     0   1       0 #> 20    1     0   0       1 #> 21    0     0   0       0 #> 22    1     0   0       0 #> 23    0     1   0       0 #> 24    1     0   1       1 #> 25    1     0   1       0 #> 26    0     0   0       1 #> 27    0     0   0       0 #> 28    0     0   1       0 #> 29    1     0   0       0 #> 30    1     1   0       1  # perform an anopa on this dataset w <- anopa( cbind(cBau,eaPoe,RnV,Placebo) ~ ., ArticleExample3, WSFactors = \"Drug(4)\") #> ANOPA::fyi: Here is how the within-subject variables are understood: #>  Drug Variable #>     1     cBau #>     2    eaPoe #>     3      RnV #>     4  Placebo  # We finish with post-hoc Tukey test e <- posthocProportions( w ) #> Not yet programmed...  # a small plot is *always* a good idea anopaPlot(w)"},{"path":"https://dcousin3.github.io/ANOPA/reference/contrastProportions.html","id":null,"dir":"Reference","previous_headings":"","what":"contrastProportion: analysis of contrasts between proportions using Anscombe transform. — contrastProportions","title":"contrastProportion: analysis of contrasts between proportions using Anscombe transform. — contrastProportions","text":"function 'contrastProportions()' performs contrasts analyses proportion data omnibus analysis obtained 'anopa()' according ANOPA framework. See lc23;textualANOPA .","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/contrastProportions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"contrastProportion: analysis of contrasts between proportions using Anscombe transform. — contrastProportions","text":"","code":"contrastProportions(w = NULL, contrasts = NULL)"},{"path":"https://dcousin3.github.io/ANOPA/reference/contrastProportions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"contrastProportion: analysis of contrasts between proportions using Anscombe transform. — contrastProportions","text":"w ANOPA object obtained anopa() emProportions(); contrasts list gives weights contrasts analyze. contrasts within list can given names distinguish . contrast weights must sum zero cross-products must equal 0 well.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/contrastProportions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"contrastProportion: analysis of contrasts between proportions using Anscombe transform. — contrastProportions","text":"table significance different contrasts.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/contrastProportions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"contrastProportion: analysis of contrasts between proportions using Anscombe transform. — contrastProportions","text":"contrastProportions() computes _F_s contrasts, testing hypothesis equals zero. contrasts 1 degree freedom, sum contrasts' degrees freedom totalize degrees freedom effect decomposed.","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/contrastProportions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"contrastProportion: analysis of contrasts between proportions using Anscombe transform. — contrastProportions","text":"","code":"# Basic example using a one between-subject factor design with the data in compiled format.  # Ficticious data present success or failure of observation classified according # to the state of residency (three levels); 175 participants have been observed in total.  # The cells are unequal: minimalBSExample #>      state  s  n #> 1  Florida 31 57 #> 2 Kentucky 25 73 #> 3  Montana  9 45  # First, perform the omnibus analysis : w <- anopa( {s;n} ~ state, minimalBSExample)  summary(w) #>             MS  df        F        p correction   Fcorr pvalcorr #> state 0.032384   2 7.335621 0.000652   1.011881 7.24949 0.000711 #> Error 0.004415 Inf                                                # Compare the first two states jointly to the third, and # compare the first to the second state: cw <- contrastProportions( w, list(          contrast1 = c(1,  1, -2)/2,          contrast2 = c(1, -1,  0) )       ) #> [1] 3 #> Not yet programmed... summary(cw) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>     -99     -99     -99     -99     -99     -99"},{"path":"https://dcousin3.github.io/ANOPA/reference/conversion.html","id":null,"dir":"Reference","previous_headings":"","what":"Converting between formats — conversion","title":"Converting between formats — conversion","text":"functions 'toWide()', 'toLong()', 'toCompiled()' converts data various formats.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/conversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converting between formats — conversion","text":"","code":"toWide(w)  toLong(w)  toCompiled(w)"},{"path":"https://dcousin3.github.io/ANOPA/reference/conversion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converting between formats — conversion","text":"w instance ANOPA object.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/conversion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converting between formats — conversion","text":"data frame requested format.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/conversion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Converting between formats — conversion","text":"proportions success set n participants can given using many formats. follows, n number participants, p number -subject factor(s), $q$ number repeated-measure factor(s). One basic format, called wide, one line per participants, 1 \"success\" observed 0 success observed. success entirely arbitrary. proportion success number 1s divided number participants group. data frame $n$ lines $p+q$ columns. second format, called long, , line, factor name(s) 1s 0s indicate success . data fame $n x q$ lines 4 columns (Id column identify participant; $p$ columns identify groups, one column identify within-subject measure given finally, 1 0 score measurement. third format, called compiled, list -subject factors number success total number participants. format compact  6 groups, data contained six lines (one line per group). format however valid -subject design infer correlation successes/failure. See vignette DataFormatsForProportions .","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/conversion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converting between formats — conversion","text":"","code":"# The minimalBSExample contains $n$ of 175 participants categorized according # to one factor $f = 1$, namely `State of residency` (with three levels)  # for 3 possible cells. minimalBSExample #>      state  s  n #> 1  Florida 31 57 #> 2 Kentucky 25 73 #> 3  Montana  9 45  # Lets incorporate the data in an ANOPA data structure w <- anopa( {s;n} ~ state, minimalBSExample )  # The data presented using various formats looks like toWide(w) #>        state s #> 1    Florida 1 #> 2    Florida 1 #> 3    Florida 1 #> 4    Florida 1 #> 5    Florida 1 #> 6    Florida 1 #> 7    Florida 1 #> 8    Florida 1 #> 9    Florida 1 #> 10   Florida 1 #> 11   Florida 1 #> 12   Florida 1 #> 13   Florida 1 #> 14   Florida 1 #> 15   Florida 1 #> 16   Florida 1 #> 17   Florida 1 #> 18   Florida 1 #> 19   Florida 1 #> 20   Florida 1 #> 21   Florida 1 #> 22   Florida 1 #> 23   Florida 1 #> 24   Florida 1 #> 25   Florida 1 #> 26   Florida 1 #> 27   Florida 1 #> 28   Florida 1 #> 29   Florida 1 #> 30   Florida 1 #> 31   Florida 1 #> 32   Florida 0 #> 33   Florida 0 #> 34   Florida 0 #> 35   Florida 0 #> 36   Florida 0 #> 37   Florida 0 #> 38   Florida 0 #> 39   Florida 0 #> 40   Florida 0 #> 41   Florida 0 #> 42   Florida 0 #> 43   Florida 0 #> 44   Florida 0 #> 45   Florida 0 #> 46   Florida 0 #> 47   Florida 0 #> 48   Florida 0 #> 49   Florida 0 #> 50   Florida 0 #> 51   Florida 0 #> 52   Florida 0 #> 53   Florida 0 #> 54   Florida 0 #> 55   Florida 0 #> 56   Florida 0 #> 57   Florida 0 #> 58  Kentucky 1 #> 59  Kentucky 1 #> 60  Kentucky 1 #> 61  Kentucky 1 #> 62  Kentucky 1 #> 63  Kentucky 1 #> 64  Kentucky 1 #> 65  Kentucky 1 #> 66  Kentucky 1 #> 67  Kentucky 1 #> 68  Kentucky 1 #> 69  Kentucky 1 #> 70  Kentucky 1 #> 71  Kentucky 1 #> 72  Kentucky 1 #> 73  Kentucky 1 #> 74  Kentucky 1 #> 75  Kentucky 1 #> 76  Kentucky 1 #> 77  Kentucky 1 #> 78  Kentucky 1 #> 79  Kentucky 1 #> 80  Kentucky 1 #> 81  Kentucky 1 #> 82  Kentucky 1 #> 83  Kentucky 0 #> 84  Kentucky 0 #> 85  Kentucky 0 #> 86  Kentucky 0 #> 87  Kentucky 0 #> 88  Kentucky 0 #> 89  Kentucky 0 #> 90  Kentucky 0 #> 91  Kentucky 0 #> 92  Kentucky 0 #> 93  Kentucky 0 #> 94  Kentucky 0 #> 95  Kentucky 0 #> 96  Kentucky 0 #> 97  Kentucky 0 #> 98  Kentucky 0 #> 99  Kentucky 0 #> 100 Kentucky 0 #> 101 Kentucky 0 #> 102 Kentucky 0 #> 103 Kentucky 0 #> 104 Kentucky 0 #> 105 Kentucky 0 #> 106 Kentucky 0 #> 107 Kentucky 0 #> 108 Kentucky 0 #> 109 Kentucky 0 #> 110 Kentucky 0 #> 111 Kentucky 0 #> 112 Kentucky 0 #> 113 Kentucky 0 #> 114 Kentucky 0 #> 115 Kentucky 0 #> 116 Kentucky 0 #> 117 Kentucky 0 #> 118 Kentucky 0 #> 119 Kentucky 0 #> 120 Kentucky 0 #> 121 Kentucky 0 #> 122 Kentucky 0 #> 123 Kentucky 0 #> 124 Kentucky 0 #> 125 Kentucky 0 #> 126 Kentucky 0 #> 127 Kentucky 0 #> 128 Kentucky 0 #> 129 Kentucky 0 #> 130 Kentucky 0 #> 131  Montana 1 #> 132  Montana 1 #> 133  Montana 1 #> 134  Montana 1 #> 135  Montana 1 #> 136  Montana 1 #> 137  Montana 1 #> 138  Montana 1 #> 139  Montana 1 #> 140  Montana 0 #> 141  Montana 0 #> 142  Montana 0 #> 143  Montana 0 #> 144  Montana 0 #> 145  Montana 0 #> 146  Montana 0 #> 147  Montana 0 #> 148  Montana 0 #> 149  Montana 0 #> 150  Montana 0 #> 151  Montana 0 #> 152  Montana 0 #> 153  Montana 0 #> 154  Montana 0 #> 155  Montana 0 #> 156  Montana 0 #> 157  Montana 0 #> 158  Montana 0 #> 159  Montana 0 #> 160  Montana 0 #> 161  Montana 0 #> 162  Montana 0 #> 163  Montana 0 #> 164  Montana 0 #> 165  Montana 0 #> 166  Montana 0 #> 167  Montana 0 #> 168  Montana 0 #> 169  Montana 0 #> 170  Montana 0 #> 171  Montana 0 #> 172  Montana 0 #> 173  Montana 0 #> 174  Montana 0 #> 175  Montana 0 # ... has 175 lines, one per participants ($n$) and 2 columns (state, success or failure)  toLong(w) #>        Id    state Variable Value #> 1.s     1  Florida        s     1 #> 2.s     2  Florida        s     1 #> 3.s     3  Florida        s     1 #> 4.s     4  Florida        s     1 #> 5.s     5  Florida        s     1 #> 6.s     6  Florida        s     1 #> 7.s     7  Florida        s     1 #> 8.s     8  Florida        s     1 #> 9.s     9  Florida        s     1 #> 10.s   10  Florida        s     1 #> 11.s   11  Florida        s     1 #> 12.s   12  Florida        s     1 #> 13.s   13  Florida        s     1 #> 14.s   14  Florida        s     1 #> 15.s   15  Florida        s     1 #> 16.s   16  Florida        s     1 #> 17.s   17  Florida        s     1 #> 18.s   18  Florida        s     1 #> 19.s   19  Florida        s     1 #> 20.s   20  Florida        s     1 #> 21.s   21  Florida        s     1 #> 22.s   22  Florida        s     1 #> 23.s   23  Florida        s     1 #> 24.s   24  Florida        s     1 #> 25.s   25  Florida        s     1 #> 26.s   26  Florida        s     1 #> 27.s   27  Florida        s     1 #> 28.s   28  Florida        s     1 #> 29.s   29  Florida        s     1 #> 30.s   30  Florida        s     1 #> 31.s   31  Florida        s     1 #> 32.s   32  Florida        s     0 #> 33.s   33  Florida        s     0 #> 34.s   34  Florida        s     0 #> 35.s   35  Florida        s     0 #> 36.s   36  Florida        s     0 #> 37.s   37  Florida        s     0 #> 38.s   38  Florida        s     0 #> 39.s   39  Florida        s     0 #> 40.s   40  Florida        s     0 #> 41.s   41  Florida        s     0 #> 42.s   42  Florida        s     0 #> 43.s   43  Florida        s     0 #> 44.s   44  Florida        s     0 #> 45.s   45  Florida        s     0 #> 46.s   46  Florida        s     0 #> 47.s   47  Florida        s     0 #> 48.s   48  Florida        s     0 #> 49.s   49  Florida        s     0 #> 50.s   50  Florida        s     0 #> 51.s   51  Florida        s     0 #> 52.s   52  Florida        s     0 #> 53.s   53  Florida        s     0 #> 54.s   54  Florida        s     0 #> 55.s   55  Florida        s     0 #> 56.s   56  Florida        s     0 #> 57.s   57  Florida        s     0 #> 58.s   58 Kentucky        s     1 #> 59.s   59 Kentucky        s     1 #> 60.s   60 Kentucky        s     1 #> 61.s   61 Kentucky        s     1 #> 62.s   62 Kentucky        s     1 #> 63.s   63 Kentucky        s     1 #> 64.s   64 Kentucky        s     1 #> 65.s   65 Kentucky        s     1 #> 66.s   66 Kentucky        s     1 #> 67.s   67 Kentucky        s     1 #> 68.s   68 Kentucky        s     1 #> 69.s   69 Kentucky        s     1 #> 70.s   70 Kentucky        s     1 #> 71.s   71 Kentucky        s     1 #> 72.s   72 Kentucky        s     1 #> 73.s   73 Kentucky        s     1 #> 74.s   74 Kentucky        s     1 #> 75.s   75 Kentucky        s     1 #> 76.s   76 Kentucky        s     1 #> 77.s   77 Kentucky        s     1 #> 78.s   78 Kentucky        s     1 #> 79.s   79 Kentucky        s     1 #> 80.s   80 Kentucky        s     1 #> 81.s   81 Kentucky        s     1 #> 82.s   82 Kentucky        s     1 #> 83.s   83 Kentucky        s     0 #> 84.s   84 Kentucky        s     0 #> 85.s   85 Kentucky        s     0 #> 86.s   86 Kentucky        s     0 #> 87.s   87 Kentucky        s     0 #> 88.s   88 Kentucky        s     0 #> 89.s   89 Kentucky        s     0 #> 90.s   90 Kentucky        s     0 #> 91.s   91 Kentucky        s     0 #> 92.s   92 Kentucky        s     0 #> 93.s   93 Kentucky        s     0 #> 94.s   94 Kentucky        s     0 #> 95.s   95 Kentucky        s     0 #> 96.s   96 Kentucky        s     0 #> 97.s   97 Kentucky        s     0 #> 98.s   98 Kentucky        s     0 #> 99.s   99 Kentucky        s     0 #> 100.s 100 Kentucky        s     0 #> 101.s 101 Kentucky        s     0 #> 102.s 102 Kentucky        s     0 #> 103.s 103 Kentucky        s     0 #> 104.s 104 Kentucky        s     0 #> 105.s 105 Kentucky        s     0 #> 106.s 106 Kentucky        s     0 #> 107.s 107 Kentucky        s     0 #> 108.s 108 Kentucky        s     0 #> 109.s 109 Kentucky        s     0 #> 110.s 110 Kentucky        s     0 #> 111.s 111 Kentucky        s     0 #> 112.s 112 Kentucky        s     0 #> 113.s 113 Kentucky        s     0 #> 114.s 114 Kentucky        s     0 #> 115.s 115 Kentucky        s     0 #> 116.s 116 Kentucky        s     0 #> 117.s 117 Kentucky        s     0 #> 118.s 118 Kentucky        s     0 #> 119.s 119 Kentucky        s     0 #> 120.s 120 Kentucky        s     0 #> 121.s 121 Kentucky        s     0 #> 122.s 122 Kentucky        s     0 #> 123.s 123 Kentucky        s     0 #> 124.s 124 Kentucky        s     0 #> 125.s 125 Kentucky        s     0 #> 126.s 126 Kentucky        s     0 #> 127.s 127 Kentucky        s     0 #> 128.s 128 Kentucky        s     0 #> 129.s 129 Kentucky        s     0 #> 130.s 130 Kentucky        s     0 #> 131.s 131  Montana        s     1 #> 132.s 132  Montana        s     1 #> 133.s 133  Montana        s     1 #> 134.s 134  Montana        s     1 #> 135.s 135  Montana        s     1 #> 136.s 136  Montana        s     1 #> 137.s 137  Montana        s     1 #> 138.s 138  Montana        s     1 #> 139.s 139  Montana        s     1 #> 140.s 140  Montana        s     0 #> 141.s 141  Montana        s     0 #> 142.s 142  Montana        s     0 #> 143.s 143  Montana        s     0 #> 144.s 144  Montana        s     0 #> 145.s 145  Montana        s     0 #> 146.s 146  Montana        s     0 #> 147.s 147  Montana        s     0 #> 148.s 148  Montana        s     0 #> 149.s 149  Montana        s     0 #> 150.s 150  Montana        s     0 #> 151.s 151  Montana        s     0 #> 152.s 152  Montana        s     0 #> 153.s 153  Montana        s     0 #> 154.s 154  Montana        s     0 #> 155.s 155  Montana        s     0 #> 156.s 156  Montana        s     0 #> 157.s 157  Montana        s     0 #> 158.s 158  Montana        s     0 #> 159.s 159  Montana        s     0 #> 160.s 160  Montana        s     0 #> 161.s 161  Montana        s     0 #> 162.s 162  Montana        s     0 #> 163.s 163  Montana        s     0 #> 164.s 164  Montana        s     0 #> 165.s 165  Montana        s     0 #> 166.s 166  Montana        s     0 #> 167.s 167  Montana        s     0 #> 168.s 168  Montana        s     0 #> 169.s 169  Montana        s     0 #> 170.s 170  Montana        s     0 #> 171.s 171  Montana        s     0 #> 172.s 172  Montana        s     0 #> 173.s 173  Montana        s     0 #> 174.s 174  Montana        s     0 #> 175.s 175  Montana        s     0 # ... has 175 lines ($n x f$) and 4 columns (participant's `Id`, state name, measure name,  # and success or failure)  toCompiled(w) #>      state  s Count #> 1  Florida 31    57 #> 2 Kentucky 25    73 #> 3  Montana  9    45 # ... has 3 lines and 3 columns ($f$ + 2: number of succes and number of participants).   # This second example is from a mixed-design. It indicates the  # state of a machine, grouped in three categories (the sole between-subject # factor) and at four different moments.  # The four measurements times are before treatment, post-treatment,  # 1 week later, and finally, 5 weeks later. minimalMxExample #>      Status bpre bpost b1week b5week #> 1    Broken    1     1      1      0 #> 2    Broken    1     1      0      0 #> 3    Broken    0     0      1      1 #> 4    Broken    1     1      1      1 #> 5    Broken    0     0      1      1 #> 6    Broken    1     0      1      1 #> 7    Broken    1     1      0      1 #> 8    Broken    0     1      1      0 #> 9  Repaired    1     1      0      0 #> 10 Repaired    0     1      0      1 #> 11 Repaired    1     1      0      0 #> 12 Repaired    0     0      1      0 #> 13 Repaired    0     0      0      0 #> 14 Repaired    1     0      0      0 #> 15 Repaired    0     0      0      0 #> 16 Repaired    0     0      0      1 #> 17 Repaired    0     0      1      0 #> 18      New    0     0      0      1 #> 19      New    0     0      1      0 #> 20      New    0     0      0      0 #> 21      New    0     0      1      0 #> 22      New    0     0      0      0 #> 23      New    0     1      0      0 #> 24      New    0     0      1      0 #> 25      New    1     1      0      0 #> 26      New    0     0      0      1 #> 27      New    1     1      1      0  # Lets incorporate the data in an ANOPA data structure w <- anopa( cbind(bpre,bpost,b1week,b5week) ~ Status,              minimalMxExample,             WSFactors = \"Moment(4)\" ) #> ANOPA::fyi: Here is how the within-subject variables are understood: #>  Moment Variable #>       1     bpre #>       2    bpost #>       3   b1week #>       4   b5week  # -- Wide format -- # Wide format is actually the format of minimalMxExample # (27 lines with 8 subjects in the first group and 9 in the second) toWide(w) #>      Status bpre bpost b1week b5week #> 1    Broken    1     1      1      0 #> 2    Broken    1     1      0      0 #> 3    Broken    0     0      1      1 #> 4    Broken    1     1      1      1 #> 5    Broken    0     0      1      1 #> 6    Broken    1     0      1      1 #> 7    Broken    1     1      0      1 #> 8    Broken    0     1      1      0 #> 9  Repaired    1     1      0      0 #> 10 Repaired    0     1      0      1 #> 11 Repaired    1     1      0      0 #> 12 Repaired    0     0      1      0 #> 13 Repaired    0     0      0      0 #> 14 Repaired    1     0      0      0 #> 15 Repaired    0     0      0      0 #> 16 Repaired    0     0      0      1 #> 17 Repaired    0     0      1      0 #> 18      New    0     0      0      1 #> 19      New    0     0      1      0 #> 20      New    0     0      0      0 #> 21      New    0     0      1      0 #> 22      New    0     0      0      0 #> 23      New    0     1      0      0 #> 24      New    0     0      1      0 #> 25      New    1     1      0      0 #> 26      New    0     0      0      1 #> 27      New    1     1      1      0  # -- Long format -- # (27 times 4 lines = 108 lines, 4 columns, that is Id, group, measurement, success or failure) toLong(w) #>           Id   Status Variable Value #> 1.bpre     1   Broken     bpre     1 #> 1.bpost    1   Broken    bpost     1 #> 1.b1week   1   Broken   b1week     1 #> 1.b5week   1   Broken   b5week     0 #> 2.bpre     2   Broken     bpre     1 #> 2.bpost    2   Broken    bpost     1 #> 2.b1week   2   Broken   b1week     0 #> 2.b5week   2   Broken   b5week     0 #> 3.bpre     3   Broken     bpre     0 #> 3.bpost    3   Broken    bpost     0 #> 3.b1week   3   Broken   b1week     1 #> 3.b5week   3   Broken   b5week     1 #> 4.bpre     4   Broken     bpre     1 #> 4.bpost    4   Broken    bpost     1 #> 4.b1week   4   Broken   b1week     1 #> 4.b5week   4   Broken   b5week     1 #> 5.bpre     5   Broken     bpre     0 #> 5.bpost    5   Broken    bpost     0 #> 5.b1week   5   Broken   b1week     1 #> 5.b5week   5   Broken   b5week     1 #> 6.bpre     6   Broken     bpre     1 #> 6.bpost    6   Broken    bpost     0 #> 6.b1week   6   Broken   b1week     1 #> 6.b5week   6   Broken   b5week     1 #> 7.bpre     7   Broken     bpre     1 #> 7.bpost    7   Broken    bpost     1 #> 7.b1week   7   Broken   b1week     0 #> 7.b5week   7   Broken   b5week     1 #> 8.bpre     8   Broken     bpre     0 #> 8.bpost    8   Broken    bpost     1 #> 8.b1week   8   Broken   b1week     1 #> 8.b5week   8   Broken   b5week     0 #> 9.bpre     9 Repaired     bpre     1 #> 9.bpost    9 Repaired    bpost     1 #> 9.b1week   9 Repaired   b1week     0 #> 9.b5week   9 Repaired   b5week     0 #> 10.bpre   10 Repaired     bpre     0 #> 10.bpost  10 Repaired    bpost     1 #> 10.b1week 10 Repaired   b1week     0 #> 10.b5week 10 Repaired   b5week     1 #> 11.bpre   11 Repaired     bpre     1 #> 11.bpost  11 Repaired    bpost     1 #> 11.b1week 11 Repaired   b1week     0 #> 11.b5week 11 Repaired   b5week     0 #> 12.bpre   12 Repaired     bpre     0 #> 12.bpost  12 Repaired    bpost     0 #> 12.b1week 12 Repaired   b1week     1 #> 12.b5week 12 Repaired   b5week     0 #> 13.bpre   13 Repaired     bpre     0 #> 13.bpost  13 Repaired    bpost     0 #> 13.b1week 13 Repaired   b1week     0 #> 13.b5week 13 Repaired   b5week     0 #> 14.bpre   14 Repaired     bpre     1 #> 14.bpost  14 Repaired    bpost     0 #> 14.b1week 14 Repaired   b1week     0 #> 14.b5week 14 Repaired   b5week     0 #> 15.bpre   15 Repaired     bpre     0 #> 15.bpost  15 Repaired    bpost     0 #> 15.b1week 15 Repaired   b1week     0 #> 15.b5week 15 Repaired   b5week     0 #> 16.bpre   16 Repaired     bpre     0 #> 16.bpost  16 Repaired    bpost     0 #> 16.b1week 16 Repaired   b1week     0 #> 16.b5week 16 Repaired   b5week     1 #> 17.bpre   17 Repaired     bpre     0 #> 17.bpost  17 Repaired    bpost     0 #> 17.b1week 17 Repaired   b1week     1 #> 17.b5week 17 Repaired   b5week     0 #> 18.bpre   18      New     bpre     0 #> 18.bpost  18      New    bpost     0 #> 18.b1week 18      New   b1week     0 #> 18.b5week 18      New   b5week     1 #> 19.bpre   19      New     bpre     0 #> 19.bpost  19      New    bpost     0 #> 19.b1week 19      New   b1week     1 #> 19.b5week 19      New   b5week     0 #> 20.bpre   20      New     bpre     0 #> 20.bpost  20      New    bpost     0 #> 20.b1week 20      New   b1week     0 #> 20.b5week 20      New   b5week     0 #> 21.bpre   21      New     bpre     0 #> 21.bpost  21      New    bpost     0 #> 21.b1week 21      New   b1week     1 #> 21.b5week 21      New   b5week     0 #> 22.bpre   22      New     bpre     0 #> 22.bpost  22      New    bpost     0 #> 22.b1week 22      New   b1week     0 #> 22.b5week 22      New   b5week     0 #> 23.bpre   23      New     bpre     0 #> 23.bpost  23      New    bpost     1 #> 23.b1week 23      New   b1week     0 #> 23.b5week 23      New   b5week     0 #> 24.bpre   24      New     bpre     0 #> 24.bpost  24      New    bpost     0 #> 24.b1week 24      New   b1week     1 #> 24.b5week 24      New   b5week     0 #> 25.bpre   25      New     bpre     1 #> 25.bpost  25      New    bpost     1 #> 25.b1week 25      New   b1week     0 #> 25.b5week 25      New   b5week     0 #> 26.bpre   26      New     bpre     0 #> 26.bpost  26      New    bpost     0 #> 26.b1week 26      New   b1week     0 #> 26.b5week 26      New   b5week     1 #> 27.bpre   27      New     bpre     1 #> 27.bpost  27      New    bpost     1 #> 27.b1week 27      New   b1week     1 #> 27.b5week 27      New   b5week     0  # -- Compiled format -- # (three lines as there are three groups, 7 columns, that is,  # the group, the 4 measurements, the number of particpants, and the # correlation between measurements for each group measured by unitary alphas) toCompiled(w) #>     Status bpre bpost b1week b5week Count      uAlpha #> 1   Broken    5     5      6      5     8 -0.15204678 #> 2      New    2     3      4      2    10 -0.03463203 #> 3 Repaired    3     3      2      2     9 -0.10416667"},{"path":"https://dcousin3.github.io/ANOPA/reference/corrected.html","id":null,"dir":"Reference","previous_headings":"","what":"corrected — corrected","title":"corrected — corrected","text":"'corrected()' provides ANOPA table corrected statistics.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/corrected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"corrected — corrected","text":"","code":"corrected(object, ...)"},{"path":"https://dcousin3.github.io/ANOPA/reference/corrected.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"corrected — corrected","text":"object object explain ... ignored","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/corrected.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"corrected — corrected","text":"ANOPA table corrected test statistics.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/emProportions.html","id":null,"dir":"Reference","previous_headings":"","what":"emProportions: simple effect analysis of proportions. — emProportions","title":"emProportions: simple effect analysis of proportions. — emProportions","text":"function 'emProportions()' performs simple effect analyses proportions omnibus analysis obtained 'anopa()' according ANOPA framework. Alternatively, also called expected marginal analysis proportions. See lc23b;textualANOPA .","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/emProportions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"emProportions: simple effect analysis of proportions. — emProportions","text":"","code":"emProportions(w, formula)"},{"path":"https://dcousin3.github.io/ANOPA/reference/emProportions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"emProportions: simple effect analysis of proportions. — emProportions","text":"w ANOPA object obtained anopa(); formula formula indicates simple effect analyze. one simple effect formula time can analyzed. formula given using vertical bar, e.g., \" ~ factorA | factorB \" obtain effect Factor within every level Factor B. dependent variable(s) (lhs equation) needed memorized w object.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/emProportions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"emProportions: simple effect analysis of proportions. — emProportions","text":"ANOPA table various simple main effects relevant, simple interaction effects.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/emProportions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"emProportions: simple effect analysis of proportions. — emProportions","text":"emProportions() computes expected marginal proportions analyzes hypothesis equal proportion. sum _F_s simple effects equal interaction main effect _F_s, additive decomposition effects.","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/emProportions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"emProportions: simple effect analysis of proportions. — emProportions","text":"","code":"# -- FIRST EXAMPLE -- # This is a basic example using a two-factors design with the factors between  # subjects. Ficticious data present the number of success according # to Class (three levels) and Difficulty (two levels) for 6 possible cells # and 72 observations in total (equal cell sizes of 12 participants in each group). twoWayExample #>   Class Difficulty success total #> 1 First       Easy      11    12 #> 2 First   Moderate       9    12 #> 3 First  Difficult       6    12 #> 4  Last       Easy      10    12 #> 5  Last   Moderate       8    12 #> 6  Last  Difficult       3    12  # As seen the data are provided in a compiled format (one line per group). # Performs the omnibus analysis first (mandatory): w <- anopa( {success;total} ~ Difficulty * Class, twoWayExample)  summary(w) #>                        MS  df        F   pvalue correction    Fcorr pvalcorr #> Difficulty       0.136787   2 6.839333 0.001071   1.027778 6.654486 0.001288 #> Class            0.032569   1 1.628455 0.201917   1.013889 1.606147 0.205034 #> Difficulty:Class 0.003660   2 0.183006 0.832763   1.243056 0.147223 0.863102 #> Error(between)   0.020000 Inf                                                 # The results shows an important interaction. You can visualize the data # using anopaPlot: anopaPlot(w)  # The interaction is overadditive, with a small differences between Difficulty # levels in the first class, but important differences between Difficulty for  # the last class.  # Let's execute the simple effect of Difficulty for every levels of Class e <- emProportions(w, ~ Difficulty | Class ) summary(e) #>                                  MS df        F   pvalue correction    Fcorr #> Difficulty | Class = First 0.050932  2 2.546587 0.078349   1.055556 2.412556 #> Difficulty | Class = Last  0.089515  2 4.475751 0.011382   1.055556 4.240186 #>                            pvalcorr #> Difficulty | Class = First 0.089586 #> Difficulty | Class = Last  0.014405   # -- SECOND EXAMPLE -- # Example using the Arrington et al. (2002) data, a 3 x 4 x 2 design involving  # Location (3 levels), Trophism (4 levels) and Diel (2 levels), all between subject. ArringtonEtAl2002 #>                 Location    Trophism      Diel    s    n #> 1                 Africa Detritivore   Diurnal   16  217 #> 2                 Africa Invertivore   Diurnal   76  498 #> 3                 Africa Invertivore Nocturnal   55  430 #> 4                 Africa    Omnivore   Diurnal    2   87 #> 5                 Africa   Piscivore   Diurnal  673  989 #> 6                 Africa   Piscivore Nocturnal  221  525 #> 7  Central/South America Detritivore   Diurnal   68 1589 #> 8  Central/South America Detritivore Nocturnal    9  318 #> 9  Central/South America Invertivore   Diurnal  706 7452 #> 10 Central/South America Invertivore Nocturnal  486 2101 #> 11 Central/South America    Omnivore   Diurnal  293 6496 #> 12 Central/South America    Omnivore Nocturnal   82  203 #> 13 Central/South America   Piscivore   Diurnal 1275 5226 #> 14 Central/South America   Piscivore Nocturnal  109  824 #> 15         North America Detritivore   Diurnal  142 1741 #> 16         North America Invertivore   Diurnal  525 3368 #> 17         North America Invertivore Nocturnal  231 1539 #> 18         North America    Omnivore   Diurnal  210 1843 #> 19         North America    Omnivore Nocturnal    7   38 #> 20         North America   Piscivore   Diurnal  536 1289 #> 21         North America   Piscivore Nocturnal   19  102  # first, we perform the omnibus analysis (mandatory): w <- anopa( {s;n} ~ Location * Trophism * Diel, ArringtonEtAl2002)  #> ANOPA::fyi(1): Combination of cells missing. Adding:  #>       Location    Trophism      Diel s n #>         Africa Detritivore Nocturnal 0 0 #>         Africa    Omnivore Nocturnal 0 0 #>  North America Detritivore Nocturnal 0 0 #> Warning: ANOPA::warning(1): Some cells have zero over zero data. Imputing... summary(w) #>                              MS  df        F   pvalue correction    Fcorr #> Location               0.027449   2 0.961802 0.382203   1.000112 0.961694 #> Trophism               0.095656   3 3.351781 0.018102   1.000115 3.351396 #> Diel                   0.029715   1 1.041227 0.307536   1.000049 1.041176 #> Location:Trophism      0.029485   6 1.033146 0.401285   1.013842 1.019041 #> Location:Diel          0.005277   2 0.184900 0.831187   1.010164 0.183040 #> Trophism:Diel          0.073769   3 2.584868 0.051365   1.012197 2.553721 #> Location:Trophism:Diel 0.011297   6 0.395837 0.882184   1.055660 0.374967 #> Error(between)         0.028539 Inf                                       #>                        pvalcorr #> Location               0.382245 #> Trophism               0.018111 #> Diel                   0.307548 #> Location:Trophism      0.410515 #> Location:Diel          0.832735 #> Trophism:Diel          0.053559 #> Location:Trophism:Diel 0.895351 #> Error(between)                   # There is a near-significant interaction of Trophism * Diel (if we consider # the unadjusted p value, but you really should consider the adjusted p value...). # If you generate the plot of the four factors, we don't see much: anopaPlot(w)   #... but a plot specifically of the interaction helps: anopaPlot(w, ~ Trophism * Diel )  # it seems that the most important difference is for omnivorous fishes # (keep in mind that there were missing cells that were imputed but there does not # exist to our knowledge agreed-upon common practices on how to impute proportions... # Are you looking for a thesis topic?).  # Let's analyse the simple effect of Trophism for every levels of Diel and Location e <- emProportions(w, ~ Trophism * Location | Diel ) summary(e) #>                                            MS df        F   pvalue correction #> Location | Diel = Diurnal            0.023357  2 0.818413 0.441131   1.000162 #> Trophism | Diel = Diurnal            0.154120  3 5.400358 0.001031   1.000130 #> Location:Trophism | Diel = Diurnal   0.013958  6 0.489075 0.817028   1.007422 #> Location | Diel = Nocturnal          0.009369  2 0.328290 0.720154   1.000429 #> Trophism | Diel = Nocturnal          0.015305  3 0.536291 0.657380   1.001707 #> Location:Trophism | Diel = Nocturnal 0.026824  6 0.939909 0.464764   2.009858 #>                                         Fcorr pvalcorr #> Location | Diel = Diurnal            0.818280 0.441190 #> Trophism | Diel = Diurnal            5.399658 0.001032 #> Location:Trophism | Diel = Diurnal   0.485472 0.819705 #> Location | Diel = Nocturnal          0.328149 0.720256 #> Trophism | Diel = Nocturnal          0.535377 0.658001 #> Location:Trophism | Diel = Nocturnal 0.467649 0.832785   # You can ask easier outputs with corrected(w) # or summary(w) for the ANOPA table only #>                              MS  df        F correction    Fcorr pvalcorr #> Location               0.027449   2 0.961802   1.000112 0.961694 0.382245 #> Trophism               0.095656   3 3.351781   1.000115 3.351396 0.018111 #> Diel                   0.029715   1 1.041227   1.000049 1.041176 0.307548 #> Location:Trophism      0.029485   6 1.033146   1.013842 1.019041 0.410515 #> Location:Diel          0.005277   2 0.184900   1.010164 0.183040 0.832735 #> Trophism:Diel          0.073769   3 2.584868   1.012197 2.553721 0.053559 #> Location:Trophism:Diel 0.011297   6 0.395837   1.055660 0.374967 0.895351 #> Error(between)         0.028539 Inf                                       explain(w)   # human-readable ouptut ((pending)) #> [1] \"method explain not yet done...\""},{"path":"https://dcousin3.github.io/ANOPA/reference/explain.html","id":null,"dir":"Reference","previous_headings":"","what":"explain — explain","title":"explain — explain","text":"'explain()' provides human-readable, exhaustive, description results. also provides references key results.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/explain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"explain — explain","text":"","code":"explain(object, ...)"},{"path":"https://dcousin3.github.io/ANOPA/reference/explain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"explain — explain","text":"object object explain ... ignored","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/explain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"explain — explain","text":"human-readable output details computations.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/minimalExamples.html","id":null,"dir":"Reference","previous_headings":"","what":"A collection of minimal Examples from various designs with one or two factors. — minimalExamples","title":"A collection of minimal Examples from various designs with one or two factors. — minimalExamples","text":"datasets present minimal examples analyzed Analysis Frequency Data method (described lc23;textualANOPA. five datasets 'minimalBSExample': example single factor (state residency) 'twoWayExample': example two factors, Class Difficulty 'minimalWSExample': example within-subject design (three measurements) 'twoWayWithinExample': example two within-subject factors 'minimalMxExample': mixed design one within one -subject factors 'minimalMxExampleCompiled': mixed design one within one -subject factors available compiled format (compact).","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/minimalExamples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A collection of minimal Examples from various designs with one or two factors. — minimalExamples","text":"","code":"minimalBSExample  twoWayExample  minimalWSExample  twoWayWithinExample  minimalMxExample  minimalMxExampleCompiled"},{"path":"https://dcousin3.github.io/ANOPA/reference/minimalExamples.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A collection of minimal Examples from various designs with one or two factors. — minimalExamples","text":"Objects class data.frame: object class data.frame 6 rows 4 columns. object class data.frame 19 rows 3 columns. object class data.frame 30 rows 6 columns. object class data.frame 27 rows 5 columns. object class data.frame 4 rows 5 columns.","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/minimalExamples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A collection of minimal Examples from various designs with one or two factors. — minimalExamples","text":"","code":"library(ANOPA)  # the twoWayExample data with proportions per Classes and Difficulty levels  twoWayExample #>   Class Difficulty success total #> 1 First       Easy      11    12 #> 2 First   Moderate       9    12 #> 3 First  Difficult       6    12 #> 4  Last       Easy      10    12 #> 5  Last   Moderate       8    12 #> 6  Last  Difficult       3    12  # perform an anopa on this dataset w <- anopa( {success;total} ~ Difficulty * Class, twoWayExample)   # We analyse the proportions by Difficulty for each Class e <- emProportions(w, ~ Difficulty | Class)"},{"path":"https://dcousin3.github.io/ANOPA/reference/posthocProportions.html","id":null,"dir":"Reference","previous_headings":"","what":"posthocProportions: post-hoc analysis of proportions. — posthocProportions","title":"posthocProportions: post-hoc analysis of proportions. — posthocProportions","text":"function 'posthocProportions()' performs post-hoc analyses proportions omnibus analysis obtained 'anopa()' according ANOPA framework. based tukey HSD test. See lc23b;textualANOPA .","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/posthocProportions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"posthocProportions: post-hoc analysis of proportions. — posthocProportions","text":"","code":"posthocProportions(w, formula)"},{"path":"https://dcousin3.github.io/ANOPA/reference/posthocProportions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"posthocProportions: post-hoc analysis of proportions. — posthocProportions","text":"w ANOPA object obtained anopa(); formula formula indicates post-hocs analyze. one simple effect formula time can analyzed. formula given using vertical bar, e.g., \" ~ factorA | factorB \" obtain effect Factor within every level Factor B.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/posthocProportions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"posthocProportions: post-hoc analysis of proportions. — posthocProportions","text":"model fit simple effect.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/posthocProportions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"posthocProportions: post-hoc analysis of proportions. — posthocProportions","text":"posthocProportions() computes expected marginal proportions analyzes hypothesis equal proportion. sum $F$s simple effects equal interaction main effect $F$s, additive decomposition effects.","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/posthocProportions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"posthocProportions: post-hoc analysis of proportions. — posthocProportions","text":"","code":"# -- FIRST EXAMPLE -- # This is a basic example using a two-factors design with the factors between  # subjects. Ficticious data present the number of success according # to Class (three levels) and Difficulty (two levels) for 6 possible cells # and 72 observations in total (equal cell sizes of 12 participants in each group). twoWayExample #>   Class Difficulty success total #> 1 First       Easy      11    12 #> 2 First   Moderate       9    12 #> 3 First  Difficult       6    12 #> 4  Last       Easy      10    12 #> 5  Last   Moderate       8    12 #> 6  Last  Difficult       3    12  # As seen the data are provided in a compiled format (one line per group). # Performs the omnibus analysis first (mandatory): w <- anopa( {success;total} ~ Class * Difficulty, twoWayExample)  summary(w) #>                        MS  df        F   pvalue correction    Fcorr pvalcorr #> Class            0.032569   1 1.628455 0.201917   1.013889 1.606147 0.205034 #> Difficulty       0.136787   2 6.839333 0.001071   1.027778 6.654486 0.001288 #> Class:Difficulty 0.003660   2 0.183006 0.832763   1.243056 0.147223 0.863102 #> Error(between)   0.020000 Inf                                                 # The results shows an important interaction. You can visualize the data # using anopaPlot: anopaPlot(w)  # The interaction is overadditive, with a small differences between Difficulty # levels in the first class, but important differences between Difficulty for  # the last class.  # Let's execute the post-hoc tests e <- posthocProportions(w, ~ Difficulty | Class ) #> Not yet programmed... summary(e) #> Length  Class   Mode  #>      0   NULL   NULL    # -- SECOND EXAMPLE -- # Example using the Arrington et al. (2002) data, a 3 x 4 x 2 design involving  # Location (3 levels), Trophism (4 levels) and Diel (2 levels), all between subject. ArringtonEtAl2002 #>                 Location    Trophism      Diel    s    n #> 1                 Africa Detritivore   Diurnal   16  217 #> 2                 Africa Invertivore   Diurnal   76  498 #> 3                 Africa Invertivore Nocturnal   55  430 #> 4                 Africa    Omnivore   Diurnal    2   87 #> 5                 Africa   Piscivore   Diurnal  673  989 #> 6                 Africa   Piscivore Nocturnal  221  525 #> 7  Central/South America Detritivore   Diurnal   68 1589 #> 8  Central/South America Detritivore Nocturnal    9  318 #> 9  Central/South America Invertivore   Diurnal  706 7452 #> 10 Central/South America Invertivore Nocturnal  486 2101 #> 11 Central/South America    Omnivore   Diurnal  293 6496 #> 12 Central/South America    Omnivore Nocturnal   82  203 #> 13 Central/South America   Piscivore   Diurnal 1275 5226 #> 14 Central/South America   Piscivore Nocturnal  109  824 #> 15         North America Detritivore   Diurnal  142 1741 #> 16         North America Invertivore   Diurnal  525 3368 #> 17         North America Invertivore Nocturnal  231 1539 #> 18         North America    Omnivore   Diurnal  210 1843 #> 19         North America    Omnivore Nocturnal    7   38 #> 20         North America   Piscivore   Diurnal  536 1289 #> 21         North America   Piscivore Nocturnal   19  102  # first, we perform the omnibus analysis (mandatory): w <- anopa( {s;n} ~ Location * Trophism * Diel, ArringtonEtAl2002)  #> ANOPA::fyi(1): Combination of cells missing. Adding:  #>       Location    Trophism      Diel s n #>         Africa Detritivore Nocturnal 0 0 #>         Africa    Omnivore Nocturnal 0 0 #>  North America Detritivore Nocturnal 0 0 #> Warning: ANOPA::warning(1): Some cells have zero over zero data. Imputing... summary(w) #>                              MS  df        F   pvalue correction    Fcorr #> Location               0.027449   2 0.961802 0.382203   1.000112 0.961694 #> Trophism               0.095656   3 3.351781 0.018102   1.000115 3.351396 #> Diel                   0.029715   1 1.041227 0.307536   1.000049 1.041176 #> Location:Trophism      0.029485   6 1.033146 0.401285   1.013842 1.019041 #> Location:Diel          0.005277   2 0.184900 0.831187   1.010164 0.183040 #> Trophism:Diel          0.073769   3 2.584868 0.051365   1.012197 2.553721 #> Location:Trophism:Diel 0.011297   6 0.395837 0.882184   1.055660 0.374967 #> Error(between)         0.028539 Inf                                       #>                        pvalcorr #> Location               0.382245 #> Trophism               0.018111 #> Diel                   0.307548 #> Location:Trophism      0.410515 #> Location:Diel          0.832735 #> Trophism:Diel          0.053559 #> Location:Trophism:Diel 0.895351 #> Error(between)                   # There is a near-significant interaction of Trophism * Diel (if we consider # the unadjusted p value, but you really should consider the adjusted p value...). # If you generate the plot of the four factors, we don't see much: # anopaPlot(w) #... but with a plot specifically of the interaction helps: anopaPlot(w, ~ Trophism * Diel )  # it seems that the most important difference is for omnivorous fishes # (keep in mind that there were missing cells that were imputed but there does not # exist to our knowledge agreed-upon common practices on how to impute proportions... # Are you looking for a thesis topic?).  # Let's analyse the simple effect of Tropism for every levels of Diel and Location e <- posthocProportions(w, ~ Tropism | Diel ) #> Not yet programmed... summary(e) #> Length  Class   Mode  #>      0   NULL   NULL    # You can ask easier outputs with summarize(w) # or summary(w) for the ANOPA table only #>                              MS  df        F   pvalue correction    Fcorr #> Location               0.027449   2 0.961802 0.382203   1.000112 0.961694 #> Trophism               0.095656   3 3.351781 0.018102   1.000115 3.351396 #> Diel                   0.029715   1 1.041227 0.307536   1.000049 1.041176 #> Location:Trophism      0.029485   6 1.033146 0.401285   1.013842 1.019041 #> Location:Diel          0.005277   2 0.184900 0.831187   1.010164 0.183040 #> Trophism:Diel          0.073769   3 2.584868 0.051365   1.012197 2.553721 #> Location:Trophism:Diel 0.011297   6 0.395837 0.882184   1.055660 0.374967 #> Error(between)         0.028539 Inf                                       #>                        pvalcorr #> Location               0.382245 #> Trophism               0.018111 #> Diel                   0.307548 #> Location:Trophism      0.410515 #> Location:Diel          0.832735 #> Trophism:Diel          0.053559 #> Location:Trophism:Diel 0.895351 #> Error(between)                  corrected(w)   # or uncorrected(w) for an abbreviated ANOPA table #>                              MS  df        F correction    Fcorr pvalcorr #> Location               0.027449   2 0.961802   1.000112 0.961694 0.382245 #> Trophism               0.095656   3 3.351781   1.000115 3.351396 0.018111 #> Diel                   0.029715   1 1.041227   1.000049 1.041176 0.307548 #> Location:Trophism      0.029485   6 1.033146   1.013842 1.019041 0.410515 #> Location:Diel          0.005277   2 0.184900   1.010164 0.183040 0.832735 #> Trophism:Diel          0.073769   3 2.584868   1.012197 2.553721 0.053559 #> Location:Trophism:Diel 0.011297   6 0.395837   1.055660 0.374967 0.895351 #> Error(between)         0.028539 Inf                                       explain(w)   # for a human-readable ouptut ((pending)) #> [1] \"method explain not yet done...\""},{"path":"https://dcousin3.github.io/ANOPA/reference/rBernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"Generating random proportions with GRP — rBernoulli","title":"Generating random proportions with GRP — rBernoulli","text":"function 'GRP()' generates random proportions based design, .e., list giving factors categories factor. data returned 'wide' format.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/rBernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generating random proportions with GRP — rBernoulli","text":"","code":"GRP( props, n, BSDesign=NULL, WSDesign=NULL, sname = \"s\" )  rBernoulli(n, p)"},{"path":"https://dcousin3.github.io/ANOPA/reference/rBernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generating random proportions with GRP — rBernoulli","text":"n many simulated participants -subject group (can vector, one per group); p proportion success; BSDesign list -subject factor(s) categories within ; WSDesign list within-subject factor(s) categories within ; props (optional) proportion succes cell design. Default 0.50; sname (optional) column name contain success/failure;","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/rBernoulli.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generating random proportions with GRP — rBernoulli","text":"GRP() returns data frame containing success (coded 1) failure (coded 0) n participants per cells design. Note correlated scores generated GRP(); see ld98ANOPA. rBernoulli() returns sequence n success (1) failures (0)","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/rBernoulli.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generating random proportions with GRP — rBernoulli","text":"name function GRP() derived GRD(), general-purpose tool generate random data ch19ANOPA now bundled superb package cgh21ANOPA. GRP() actually proxy GRD().","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/rBernoulli.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generating random proportions with GRP — rBernoulli","text":"","code":"# The first example generate scorse for 20 particants in one factor having # two categories (low and high): design <- list( A=c(\"low\",\"high\")) GRP( design, props = c(0.1,  0.9), n = 20 ) #>    id    A s #> 1   1  low 0 #> 2   2  low 0 #> 3   3  low 0 #> 4   4  low 0 #> 5   5  low 0 #> 6   6  low 0 #> 7   7  low 0 #> 8   8  low 0 #> 9   9  low 0 #> 10 10  low 0 #> 11 11  low 0 #> 12 12  low 0 #> 13 13  low 0 #> 14 14  low 0 #> 15 15  low 0 #> 16 16  low 0 #> 17 17  low 0 #> 18 18  low 0 #> 19 19  low 0 #> 20 20  low 1 #> 21 21 high 1 #> 22 22 high 1 #> 23 23 high 1 #> 24 24 high 1 #> 25 25 high 1 #> 26 26 high 1 #> 27 27 high 1 #> 28 28 high 1 #> 29 29 high 1 #> 30 30 high 1 #> 31 31 high 0 #> 32 32 high 1 #> 33 33 high 1 #> 34 34 high 1 #> 35 35 high 1 #> 36 36 high 1 #> 37 37 high 1 #> 38 38 high 1 #> 39 39 high 1 #> 40 40 high 1  # This example has two factors, with factor A having levels a, b, c # and factor B having 2 levels, for a total of 6 conditions; # with 40 participants per group, it represents 240 observations: design <- list( A=letters[1:3], B = c(\"low\",\"high\")) GRP( design, props = c(0.1, 0.15, 0.20, 0.80, 0.85, 0.90), n = 40 ) #>      id A    B s #> 1     1 a  low 0 #> 2     2 a  low 0 #> 3     3 a  low 0 #> 4     4 a  low 0 #> 5     5 a  low 1 #> 6     6 a  low 0 #> 7     7 a  low 0 #> 8     8 a  low 0 #> 9     9 a  low 0 #> 10   10 a  low 0 #> 11   11 a  low 0 #> 12   12 a  low 0 #> 13   13 a  low 0 #> 14   14 a  low 0 #> 15   15 a  low 0 #> 16   16 a  low 0 #> 17   17 a  low 0 #> 18   18 a  low 0 #> 19   19 a  low 0 #> 20   20 a  low 0 #> 21   21 a  low 0 #> 22   22 a  low 1 #> 23   23 a  low 0 #> 24   24 a  low 0 #> 25   25 a  low 1 #> 26   26 a  low 0 #> 27   27 a  low 0 #> 28   28 a  low 0 #> 29   29 a  low 0 #> 30   30 a  low 0 #> 31   31 a  low 0 #> 32   32 a  low 0 #> 33   33 a  low 0 #> 34   34 a  low 0 #> 35   35 a  low 0 #> 36   36 a  low 0 #> 37   37 a  low 0 #> 38   38 a  low 0 #> 39   39 a  low 0 #> 40   40 a  low 0 #> 41   41 b  low 0 #> 42   42 b  low 0 #> 43   43 b  low 0 #> 44   44 b  low 0 #> 45   45 b  low 0 #> 46   46 b  low 0 #> 47   47 b  low 0 #> 48   48 b  low 1 #> 49   49 b  low 0 #> 50   50 b  low 0 #> 51   51 b  low 0 #> 52   52 b  low 1 #> 53   53 b  low 0 #> 54   54 b  low 0 #> 55   55 b  low 0 #> 56   56 b  low 0 #> 57   57 b  low 0 #> 58   58 b  low 0 #> 59   59 b  low 1 #> 60   60 b  low 0 #> 61   61 b  low 0 #> 62   62 b  low 0 #> 63   63 b  low 0 #> 64   64 b  low 0 #> 65   65 b  low 0 #> 66   66 b  low 0 #> 67   67 b  low 0 #> 68   68 b  low 0 #> 69   69 b  low 0 #> 70   70 b  low 0 #> 71   71 b  low 0 #> 72   72 b  low 0 #> 73   73 b  low 0 #> 74   74 b  low 0 #> 75   75 b  low 0 #> 76   76 b  low 0 #> 77   77 b  low 0 #> 78   78 b  low 0 #> 79   79 b  low 0 #> 80   80 b  low 0 #> 81   81 c  low 0 #> 82   82 c  low 0 #> 83   83 c  low 1 #> 84   84 c  low 0 #> 85   85 c  low 0 #> 86   86 c  low 0 #> 87   87 c  low 1 #> 88   88 c  low 1 #> 89   89 c  low 1 #> 90   90 c  low 1 #> 91   91 c  low 0 #> 92   92 c  low 0 #> 93   93 c  low 1 #> 94   94 c  low 0 #> 95   95 c  low 0 #> 96   96 c  low 1 #> 97   97 c  low 0 #> 98   98 c  low 0 #> 99   99 c  low 0 #> 100 100 c  low 1 #> 101 101 c  low 0 #> 102 102 c  low 1 #> 103 103 c  low 0 #> 104 104 c  low 0 #> 105 105 c  low 0 #> 106 106 c  low 0 #> 107 107 c  low 0 #> 108 108 c  low 0 #> 109 109 c  low 0 #> 110 110 c  low 0 #> 111 111 c  low 0 #> 112 112 c  low 0 #> 113 113 c  low 0 #> 114 114 c  low 1 #> 115 115 c  low 1 #> 116 116 c  low 0 #> 117 117 c  low 0 #> 118 118 c  low 0 #> 119 119 c  low 0 #> 120 120 c  low 0 #> 121 121 a high 1 #> 122 122 a high 1 #> 123 123 a high 0 #> 124 124 a high 0 #> 125 125 a high 1 #> 126 126 a high 1 #> 127 127 a high 1 #> 128 128 a high 1 #> 129 129 a high 0 #> 130 130 a high 1 #> 131 131 a high 1 #> 132 132 a high 1 #> 133 133 a high 1 #> 134 134 a high 1 #> 135 135 a high 0 #> 136 136 a high 0 #> 137 137 a high 1 #> 138 138 a high 1 #> 139 139 a high 1 #> 140 140 a high 1 #> 141 141 a high 0 #> 142 142 a high 1 #> 143 143 a high 1 #> 144 144 a high 1 #> 145 145 a high 1 #> 146 146 a high 1 #> 147 147 a high 1 #> 148 148 a high 1 #> 149 149 a high 1 #> 150 150 a high 1 #> 151 151 a high 1 #> 152 152 a high 1 #> 153 153 a high 0 #> 154 154 a high 1 #> 155 155 a high 1 #> 156 156 a high 1 #> 157 157 a high 1 #> 158 158 a high 0 #> 159 159 a high 1 #> 160 160 a high 1 #> 161 161 b high 1 #> 162 162 b high 1 #> 163 163 b high 1 #> 164 164 b high 1 #> 165 165 b high 1 #> 166 166 b high 1 #> 167 167 b high 1 #> 168 168 b high 1 #> 169 169 b high 1 #> 170 170 b high 1 #> 171 171 b high 1 #> 172 172 b high 1 #> 173 173 b high 0 #> 174 174 b high 1 #> 175 175 b high 1 #> 176 176 b high 1 #> 177 177 b high 1 #> 178 178 b high 0 #> 179 179 b high 1 #> 180 180 b high 0 #> 181 181 b high 1 #> 182 182 b high 1 #> 183 183 b high 1 #> 184 184 b high 1 #> 185 185 b high 1 #> 186 186 b high 1 #> 187 187 b high 1 #> 188 188 b high 1 #> 189 189 b high 1 #> 190 190 b high 1 #> 191 191 b high 0 #> 192 192 b high 1 #> 193 193 b high 0 #> 194 194 b high 1 #> 195 195 b high 1 #> 196 196 b high 1 #> 197 197 b high 1 #> 198 198 b high 0 #> 199 199 b high 1 #> 200 200 b high 1 #> 201 201 c high 1 #> 202 202 c high 1 #> 203 203 c high 1 #> 204 204 c high 1 #> 205 205 c high 1 #> 206 206 c high 1 #> 207 207 c high 1 #> 208 208 c high 1 #> 209 209 c high 0 #> 210 210 c high 1 #> 211 211 c high 1 #> 212 212 c high 1 #> 213 213 c high 0 #> 214 214 c high 1 #> 215 215 c high 1 #> 216 216 c high 1 #> 217 217 c high 1 #> 218 218 c high 1 #> 219 219 c high 1 #> 220 220 c high 1 #> 221 221 c high 1 #> 222 222 c high 1 #> 223 223 c high 1 #> 224 224 c high 1 #> 225 225 c high 0 #> 226 226 c high 1 #> 227 227 c high 1 #> 228 228 c high 1 #> 229 229 c high 1 #> 230 230 c high 1 #> 231 231 c high 1 #> 232 232 c high 1 #> 233 233 c high 1 #> 234 234 c high 1 #> 235 235 c high 1 #> 236 236 c high 1 #> 237 237 c high 1 #> 238 238 c high 1 #> 239 239 c high 1 #> 240 240 c high 1  # groups can be unequal: design <- list( A=c(\"low\",\"high\")) GRP( design, props = c(0.1,  0.9), n = c(5, 35) ) #>    id    A s #> 1   1  low 0 #> 2   2  low 0 #> 3   3  low 0 #> 4   4  low 0 #> 5   5  low 0 #> 6   6 high 1 #> 7   7 high 1 #> 8   8 high 1 #> 9   9 high 1 #> 10 10 high 1 #> 11 11 high 1 #> 12 12 high 1 #> 13 13 high 1 #> 14 14 high 1 #> 15 15 high 1 #> 16 16 high 1 #> 17 17 high 1 #> 18 18 high 1 #> 19 19 high 1 #> 20 20 high 1 #> 21 21 high 1 #> 22 22 high 1 #> 23 23 high 1 #> 24 24 high 1 #> 25 25 high 1 #> 26 26 high 1 #> 27 27 high 0 #> 28 28 high 0 #> 29 29 high 1 #> 30 30 high 1 #> 31 31 high 1 #> 32 32 high 1 #> 33 33 high 1 #> 34 34 high 1 #> 35 35 high 1 #> 36 36 high 1 #> 37 37 high 1 #> 38 38 high 1 #> 39 39 high 1 #> 40 40 high 1  # Finally, repeated-measures can be generated # but note that correlated scores cannot be generated with `GRP()` wsDesign = list( Moment = c(\"pre\", \"post\") ) GRP( WSDesign=wsDesign, props = c(0.1,  0.9), n = 10 ) #>    id s.pre s.post #> 1   1     1      1 #> 2   2     0      0 #> 3   3     0      1 #> 4   4     0      1 #> 5   5     0      1 #> 6   6     1      1 #> 7   7     0      0 #> 8   8     0      1 #> 9   9     0      1 #> 10 10     0      0  # This last one has three factors, for a total of 3 x 2 x 2 = 12 cells design <- list( A=letters[1:3], B = c(\"low\",\"high\"), C = c(\"cat\",\"dog\")) GRP( design, n = 30, props = rep(0.5,12) ) #>      id A    B   C s #> 1     1 a  low cat 1 #> 2     2 a  low cat 0 #> 3     3 a  low cat 1 #> 4     4 a  low cat 0 #> 5     5 a  low cat 0 #> 6     6 a  low cat 1 #> 7     7 a  low cat 1 #> 8     8 a  low cat 1 #> 9     9 a  low cat 0 #> 10   10 a  low cat 0 #> 11   11 a  low cat 1 #> 12   12 a  low cat 1 #> 13   13 a  low cat 0 #> 14   14 a  low cat 0 #> 15   15 a  low cat 1 #> 16   16 a  low cat 1 #> 17   17 a  low cat 1 #> 18   18 a  low cat 1 #> 19   19 a  low cat 1 #> 20   20 a  low cat 1 #> 21   21 a  low cat 1 #> 22   22 a  low cat 0 #> 23   23 a  low cat 0 #> 24   24 a  low cat 1 #> 25   25 a  low cat 1 #> 26   26 a  low cat 0 #> 27   27 a  low cat 1 #> 28   28 a  low cat 1 #> 29   29 a  low cat 0 #> 30   30 a  low cat 1 #> 31   31 b  low cat 1 #> 32   32 b  low cat 0 #> 33   33 b  low cat 0 #> 34   34 b  low cat 1 #> 35   35 b  low cat 0 #> 36   36 b  low cat 1 #> 37   37 b  low cat 1 #> 38   38 b  low cat 0 #> 39   39 b  low cat 1 #> 40   40 b  low cat 1 #> 41   41 b  low cat 0 #> 42   42 b  low cat 0 #> 43   43 b  low cat 1 #> 44   44 b  low cat 0 #> 45   45 b  low cat 0 #> 46   46 b  low cat 0 #> 47   47 b  low cat 0 #> 48   48 b  low cat 0 #> 49   49 b  low cat 0 #> 50   50 b  low cat 0 #> 51   51 b  low cat 0 #> 52   52 b  low cat 0 #> 53   53 b  low cat 0 #> 54   54 b  low cat 0 #> 55   55 b  low cat 1 #> 56   56 b  low cat 1 #> 57   57 b  low cat 0 #> 58   58 b  low cat 1 #> 59   59 b  low cat 1 #> 60   60 b  low cat 1 #> 61   61 c  low cat 1 #> 62   62 c  low cat 1 #> 63   63 c  low cat 1 #> 64   64 c  low cat 0 #> 65   65 c  low cat 0 #> 66   66 c  low cat 0 #> 67   67 c  low cat 1 #> 68   68 c  low cat 1 #> 69   69 c  low cat 1 #> 70   70 c  low cat 0 #> 71   71 c  low cat 0 #> 72   72 c  low cat 0 #> 73   73 c  low cat 1 #> 74   74 c  low cat 0 #> 75   75 c  low cat 1 #> 76   76 c  low cat 1 #> 77   77 c  low cat 0 #> 78   78 c  low cat 1 #> 79   79 c  low cat 1 #> 80   80 c  low cat 0 #> 81   81 c  low cat 0 #> 82   82 c  low cat 0 #> 83   83 c  low cat 0 #> 84   84 c  low cat 0 #> 85   85 c  low cat 1 #> 86   86 c  low cat 0 #> 87   87 c  low cat 0 #> 88   88 c  low cat 1 #> 89   89 c  low cat 1 #> 90   90 c  low cat 1 #> 91   91 a high cat 0 #> 92   92 a high cat 0 #> 93   93 a high cat 1 #> 94   94 a high cat 1 #> 95   95 a high cat 0 #> 96   96 a high cat 0 #> 97   97 a high cat 1 #> 98   98 a high cat 0 #> 99   99 a high cat 0 #> 100 100 a high cat 0 #> 101 101 a high cat 0 #> 102 102 a high cat 0 #> 103 103 a high cat 0 #> 104 104 a high cat 1 #> 105 105 a high cat 1 #> 106 106 a high cat 0 #> 107 107 a high cat 0 #> 108 108 a high cat 0 #> 109 109 a high cat 1 #> 110 110 a high cat 0 #> 111 111 a high cat 1 #> 112 112 a high cat 0 #> 113 113 a high cat 1 #> 114 114 a high cat 1 #> 115 115 a high cat 1 #> 116 116 a high cat 1 #> 117 117 a high cat 0 #> 118 118 a high cat 1 #> 119 119 a high cat 0 #> 120 120 a high cat 0 #> 121 121 b high cat 1 #> 122 122 b high cat 0 #> 123 123 b high cat 1 #> 124 124 b high cat 1 #> 125 125 b high cat 1 #> 126 126 b high cat 1 #> 127 127 b high cat 0 #> 128 128 b high cat 0 #> 129 129 b high cat 1 #> 130 130 b high cat 0 #> 131 131 b high cat 0 #> 132 132 b high cat 1 #> 133 133 b high cat 1 #> 134 134 b high cat 1 #> 135 135 b high cat 1 #> 136 136 b high cat 1 #> 137 137 b high cat 0 #> 138 138 b high cat 1 #> 139 139 b high cat 0 #> 140 140 b high cat 1 #> 141 141 b high cat 0 #> 142 142 b high cat 1 #> 143 143 b high cat 0 #> 144 144 b high cat 0 #> 145 145 b high cat 0 #> 146 146 b high cat 1 #> 147 147 b high cat 1 #> 148 148 b high cat 0 #> 149 149 b high cat 1 #> 150 150 b high cat 0 #> 151 151 c high cat 0 #> 152 152 c high cat 1 #> 153 153 c high cat 0 #> 154 154 c high cat 1 #> 155 155 c high cat 1 #> 156 156 c high cat 0 #> 157 157 c high cat 0 #> 158 158 c high cat 1 #> 159 159 c high cat 0 #> 160 160 c high cat 0 #> 161 161 c high cat 1 #> 162 162 c high cat 0 #> 163 163 c high cat 0 #> 164 164 c high cat 1 #> 165 165 c high cat 1 #> 166 166 c high cat 1 #> 167 167 c high cat 1 #> 168 168 c high cat 0 #> 169 169 c high cat 1 #> 170 170 c high cat 0 #> 171 171 c high cat 1 #> 172 172 c high cat 0 #> 173 173 c high cat 1 #> 174 174 c high cat 1 #> 175 175 c high cat 1 #> 176 176 c high cat 1 #> 177 177 c high cat 1 #> 178 178 c high cat 0 #> 179 179 c high cat 1 #> 180 180 c high cat 1 #> 181 181 a  low dog 0 #> 182 182 a  low dog 1 #> 183 183 a  low dog 1 #> 184 184 a  low dog 1 #> 185 185 a  low dog 1 #> 186 186 a  low dog 1 #> 187 187 a  low dog 0 #> 188 188 a  low dog 0 #> 189 189 a  low dog 0 #> 190 190 a  low dog 1 #> 191 191 a  low dog 0 #> 192 192 a  low dog 0 #> 193 193 a  low dog 0 #> 194 194 a  low dog 1 #> 195 195 a  low dog 0 #> 196 196 a  low dog 1 #> 197 197 a  low dog 0 #> 198 198 a  low dog 0 #> 199 199 a  low dog 1 #> 200 200 a  low dog 0 #> 201 201 a  low dog 1 #> 202 202 a  low dog 0 #> 203 203 a  low dog 1 #> 204 204 a  low dog 1 #> 205 205 a  low dog 0 #> 206 206 a  low dog 0 #> 207 207 a  low dog 1 #> 208 208 a  low dog 0 #> 209 209 a  low dog 0 #> 210 210 a  low dog 0 #> 211 211 b  low dog 1 #> 212 212 b  low dog 1 #> 213 213 b  low dog 1 #> 214 214 b  low dog 1 #> 215 215 b  low dog 0 #> 216 216 b  low dog 1 #> 217 217 b  low dog 1 #> 218 218 b  low dog 0 #> 219 219 b  low dog 0 #> 220 220 b  low dog 1 #> 221 221 b  low dog 0 #> 222 222 b  low dog 0 #> 223 223 b  low dog 0 #> 224 224 b  low dog 1 #> 225 225 b  low dog 0 #> 226 226 b  low dog 0 #> 227 227 b  low dog 0 #> 228 228 b  low dog 0 #> 229 229 b  low dog 1 #> 230 230 b  low dog 0 #> 231 231 b  low dog 0 #> 232 232 b  low dog 1 #> 233 233 b  low dog 1 #> 234 234 b  low dog 1 #> 235 235 b  low dog 1 #> 236 236 b  low dog 0 #> 237 237 b  low dog 0 #> 238 238 b  low dog 1 #> 239 239 b  low dog 1 #> 240 240 b  low dog 1 #> 241 241 c  low dog 1 #> 242 242 c  low dog 1 #> 243 243 c  low dog 1 #> 244 244 c  low dog 0 #> 245 245 c  low dog 1 #> 246 246 c  low dog 0 #> 247 247 c  low dog 1 #> 248 248 c  low dog 0 #> 249 249 c  low dog 0 #> 250 250 c  low dog 0 #> 251 251 c  low dog 0 #> 252 252 c  low dog 1 #> 253 253 c  low dog 0 #> 254 254 c  low dog 0 #> 255 255 c  low dog 0 #> 256 256 c  low dog 0 #> 257 257 c  low dog 1 #> 258 258 c  low dog 1 #> 259 259 c  low dog 1 #> 260 260 c  low dog 1 #> 261 261 c  low dog 1 #> 262 262 c  low dog 1 #> 263 263 c  low dog 0 #> 264 264 c  low dog 1 #> 265 265 c  low dog 1 #> 266 266 c  low dog 1 #> 267 267 c  low dog 0 #> 268 268 c  low dog 0 #> 269 269 c  low dog 0 #> 270 270 c  low dog 1 #> 271 271 a high dog 1 #> 272 272 a high dog 0 #> 273 273 a high dog 0 #> 274 274 a high dog 0 #> 275 275 a high dog 0 #> 276 276 a high dog 0 #> 277 277 a high dog 0 #> 278 278 a high dog 0 #> 279 279 a high dog 0 #> 280 280 a high dog 1 #> 281 281 a high dog 1 #> 282 282 a high dog 1 #> 283 283 a high dog 0 #> 284 284 a high dog 1 #> 285 285 a high dog 1 #> 286 286 a high dog 0 #> 287 287 a high dog 0 #> 288 288 a high dog 1 #> 289 289 a high dog 0 #> 290 290 a high dog 0 #> 291 291 a high dog 0 #> 292 292 a high dog 1 #> 293 293 a high dog 0 #> 294 294 a high dog 1 #> 295 295 a high dog 1 #> 296 296 a high dog 0 #> 297 297 a high dog 0 #> 298 298 a high dog 0 #> 299 299 a high dog 1 #> 300 300 a high dog 1 #> 301 301 b high dog 1 #> 302 302 b high dog 1 #> 303 303 b high dog 0 #> 304 304 b high dog 0 #> 305 305 b high dog 1 #> 306 306 b high dog 1 #> 307 307 b high dog 0 #> 308 308 b high dog 0 #> 309 309 b high dog 1 #> 310 310 b high dog 1 #> 311 311 b high dog 0 #> 312 312 b high dog 1 #> 313 313 b high dog 1 #> 314 314 b high dog 1 #> 315 315 b high dog 0 #> 316 316 b high dog 1 #> 317 317 b high dog 0 #> 318 318 b high dog 1 #> 319 319 b high dog 1 #> 320 320 b high dog 1 #> 321 321 b high dog 0 #> 322 322 b high dog 0 #> 323 323 b high dog 0 #> 324 324 b high dog 1 #> 325 325 b high dog 0 #> 326 326 b high dog 1 #> 327 327 b high dog 1 #> 328 328 b high dog 1 #> 329 329 b high dog 0 #> 330 330 b high dog 1 #> 331 331 c high dog 0 #> 332 332 c high dog 0 #> 333 333 c high dog 1 #> 334 334 c high dog 1 #> 335 335 c high dog 0 #> 336 336 c high dog 0 #> 337 337 c high dog 0 #> 338 338 c high dog 0 #> 339 339 c high dog 0 #> 340 340 c high dog 1 #> 341 341 c high dog 1 #> 342 342 c high dog 1 #> 343 343 c high dog 0 #> 344 344 c high dog 1 #> 345 345 c high dog 0 #> 346 346 c high dog 0 #> 347 347 c high dog 0 #> 348 348 c high dog 0 #> 349 349 c high dog 0 #> 350 350 c high dog 1 #> 351 351 c high dog 1 #> 352 352 c high dog 0 #> 353 353 c high dog 0 #> 354 354 c high dog 0 #> 355 355 c high dog 0 #> 356 356 c high dog 1 #> 357 357 c high dog 1 #> 358 358 c high dog 0 #> 359 359 c high dog 1 #> 360 360 c high dog 1  # To specify unequal probabilities, use design  <- list( A=letters[1:3], B = c(\"low\",\"high\")) expProp <- c(.05, .05, .35, .35, .10, .10 ) GRP( design, n = 30, props=expProp ) #>      id A    B s #> 1     1 a  low 0 #> 2     2 a  low 0 #> 3     3 a  low 0 #> 4     4 a  low 0 #> 5     5 a  low 0 #> 6     6 a  low 0 #> 7     7 a  low 0 #> 8     8 a  low 0 #> 9     9 a  low 0 #> 10   10 a  low 1 #> 11   11 a  low 0 #> 12   12 a  low 0 #> 13   13 a  low 0 #> 14   14 a  low 0 #> 15   15 a  low 0 #> 16   16 a  low 0 #> 17   17 a  low 0 #> 18   18 a  low 0 #> 19   19 a  low 0 #> 20   20 a  low 0 #> 21   21 a  low 0 #> 22   22 a  low 0 #> 23   23 a  low 0 #> 24   24 a  low 0 #> 25   25 a  low 0 #> 26   26 a  low 0 #> 27   27 a  low 0 #> 28   28 a  low 0 #> 29   29 a  low 0 #> 30   30 a  low 0 #> 31   31 b  low 0 #> 32   32 b  low 0 #> 33   33 b  low 0 #> 34   34 b  low 0 #> 35   35 b  low 0 #> 36   36 b  low 0 #> 37   37 b  low 0 #> 38   38 b  low 0 #> 39   39 b  low 0 #> 40   40 b  low 0 #> 41   41 b  low 0 #> 42   42 b  low 0 #> 43   43 b  low 0 #> 44   44 b  low 0 #> 45   45 b  low 0 #> 46   46 b  low 0 #> 47   47 b  low 0 #> 48   48 b  low 0 #> 49   49 b  low 0 #> 50   50 b  low 0 #> 51   51 b  low 0 #> 52   52 b  low 0 #> 53   53 b  low 0 #> 54   54 b  low 1 #> 55   55 b  low 0 #> 56   56 b  low 0 #> 57   57 b  low 0 #> 58   58 b  low 0 #> 59   59 b  low 0 #> 60   60 b  low 0 #> 61   61 c  low 0 #> 62   62 c  low 0 #> 63   63 c  low 0 #> 64   64 c  low 0 #> 65   65 c  low 0 #> 66   66 c  low 1 #> 67   67 c  low 0 #> 68   68 c  low 0 #> 69   69 c  low 1 #> 70   70 c  low 0 #> 71   71 c  low 0 #> 72   72 c  low 0 #> 73   73 c  low 0 #> 74   74 c  low 0 #> 75   75 c  low 1 #> 76   76 c  low 1 #> 77   77 c  low 0 #> 78   78 c  low 0 #> 79   79 c  low 0 #> 80   80 c  low 1 #> 81   81 c  low 1 #> 82   82 c  low 0 #> 83   83 c  low 1 #> 84   84 c  low 0 #> 85   85 c  low 1 #> 86   86 c  low 1 #> 87   87 c  low 0 #> 88   88 c  low 0 #> 89   89 c  low 1 #> 90   90 c  low 0 #> 91   91 a high 0 #> 92   92 a high 1 #> 93   93 a high 0 #> 94   94 a high 1 #> 95   95 a high 0 #> 96   96 a high 0 #> 97   97 a high 1 #> 98   98 a high 1 #> 99   99 a high 1 #> 100 100 a high 0 #> 101 101 a high 0 #> 102 102 a high 0 #> 103 103 a high 0 #> 104 104 a high 1 #> 105 105 a high 0 #> 106 106 a high 0 #> 107 107 a high 1 #> 108 108 a high 0 #> 109 109 a high 0 #> 110 110 a high 0 #> 111 111 a high 1 #> 112 112 a high 0 #> 113 113 a high 0 #> 114 114 a high 0 #> 115 115 a high 0 #> 116 116 a high 1 #> 117 117 a high 1 #> 118 118 a high 0 #> 119 119 a high 0 #> 120 120 a high 0 #> 121 121 b high 0 #> 122 122 b high 0 #> 123 123 b high 0 #> 124 124 b high 0 #> 125 125 b high 0 #> 126 126 b high 0 #> 127 127 b high 0 #> 128 128 b high 0 #> 129 129 b high 0 #> 130 130 b high 0 #> 131 131 b high 0 #> 132 132 b high 0 #> 133 133 b high 0 #> 134 134 b high 0 #> 135 135 b high 0 #> 136 136 b high 0 #> 137 137 b high 0 #> 138 138 b high 0 #> 139 139 b high 0 #> 140 140 b high 0 #> 141 141 b high 0 #> 142 142 b high 0 #> 143 143 b high 0 #> 144 144 b high 0 #> 145 145 b high 0 #> 146 146 b high 0 #> 147 147 b high 1 #> 148 148 b high 0 #> 149 149 b high 0 #> 150 150 b high 0 #> 151 151 c high 0 #> 152 152 c high 0 #> 153 153 c high 0 #> 154 154 c high 0 #> 155 155 c high 0 #> 156 156 c high 0 #> 157 157 c high 0 #> 158 158 c high 0 #> 159 159 c high 0 #> 160 160 c high 0 #> 161 161 c high 0 #> 162 162 c high 0 #> 163 163 c high 0 #> 164 164 c high 0 #> 165 165 c high 0 #> 166 166 c high 0 #> 167 167 c high 0 #> 168 168 c high 0 #> 169 169 c high 0 #> 170 170 c high 0 #> 171 171 c high 0 #> 172 172 c high 0 #> 173 173 c high 1 #> 174 174 c high 0 #> 175 175 c high 0 #> 176 176 c high 0 #> 177 177 c high 0 #> 178 178 c high 0 #> 179 179 c high 1 #> 180 180 c high 0  # The name of the column containing the proportions can be changed GRP( design, n=30, props=expProp, sname=\"patate\") #>      id A    B patate #> 1     1 a  low      0 #> 2     2 a  low      0 #> 3     3 a  low      0 #> 4     4 a  low      0 #> 5     5 a  low      0 #> 6     6 a  low      0 #> 7     7 a  low      0 #> 8     8 a  low      0 #> 9     9 a  low      0 #> 10   10 a  low      0 #> 11   11 a  low      0 #> 12   12 a  low      0 #> 13   13 a  low      1 #> 14   14 a  low      0 #> 15   15 a  low      0 #> 16   16 a  low      0 #> 17   17 a  low      0 #> 18   18 a  low      0 #> 19   19 a  low      0 #> 20   20 a  low      0 #> 21   21 a  low      0 #> 22   22 a  low      0 #> 23   23 a  low      0 #> 24   24 a  low      0 #> 25   25 a  low      0 #> 26   26 a  low      0 #> 27   27 a  low      0 #> 28   28 a  low      0 #> 29   29 a  low      1 #> 30   30 a  low      0 #> 31   31 b  low      0 #> 32   32 b  low      0 #> 33   33 b  low      0 #> 34   34 b  low      0 #> 35   35 b  low      0 #> 36   36 b  low      0 #> 37   37 b  low      0 #> 38   38 b  low      0 #> 39   39 b  low      0 #> 40   40 b  low      0 #> 41   41 b  low      0 #> 42   42 b  low      0 #> 43   43 b  low      0 #> 44   44 b  low      1 #> 45   45 b  low      0 #> 46   46 b  low      0 #> 47   47 b  low      0 #> 48   48 b  low      0 #> 49   49 b  low      0 #> 50   50 b  low      0 #> 51   51 b  low      0 #> 52   52 b  low      0 #> 53   53 b  low      0 #> 54   54 b  low      0 #> 55   55 b  low      0 #> 56   56 b  low      0 #> 57   57 b  low      0 #> 58   58 b  low      0 #> 59   59 b  low      0 #> 60   60 b  low      0 #> 61   61 c  low      1 #> 62   62 c  low      0 #> 63   63 c  low      0 #> 64   64 c  low      0 #> 65   65 c  low      1 #> 66   66 c  low      0 #> 67   67 c  low      1 #> 68   68 c  low      0 #> 69   69 c  low      0 #> 70   70 c  low      0 #> 71   71 c  low      1 #> 72   72 c  low      1 #> 73   73 c  low      0 #> 74   74 c  low      0 #> 75   75 c  low      0 #> 76   76 c  low      0 #> 77   77 c  low      1 #> 78   78 c  low      0 #> 79   79 c  low      0 #> 80   80 c  low      0 #> 81   81 c  low      0 #> 82   82 c  low      0 #> 83   83 c  low      0 #> 84   84 c  low      1 #> 85   85 c  low      1 #> 86   86 c  low      1 #> 87   87 c  low      0 #> 88   88 c  low      0 #> 89   89 c  low      1 #> 90   90 c  low      1 #> 91   91 a high      1 #> 92   92 a high      1 #> 93   93 a high      1 #> 94   94 a high      0 #> 95   95 a high      1 #> 96   96 a high      0 #> 97   97 a high      1 #> 98   98 a high      1 #> 99   99 a high      0 #> 100 100 a high      0 #> 101 101 a high      0 #> 102 102 a high      0 #> 103 103 a high      0 #> 104 104 a high      1 #> 105 105 a high      0 #> 106 106 a high      0 #> 107 107 a high      0 #> 108 108 a high      0 #> 109 109 a high      0 #> 110 110 a high      1 #> 111 111 a high      1 #> 112 112 a high      0 #> 113 113 a high      1 #> 114 114 a high      1 #> 115 115 a high      0 #> 116 116 a high      1 #> 117 117 a high      1 #> 118 118 a high      0 #> 119 119 a high      0 #> 120 120 a high      0 #> 121 121 b high      0 #> 122 122 b high      0 #> 123 123 b high      0 #> 124 124 b high      0 #> 125 125 b high      0 #> 126 126 b high      0 #> 127 127 b high      0 #> 128 128 b high      0 #> 129 129 b high      0 #> 130 130 b high      0 #> 131 131 b high      0 #> 132 132 b high      0 #> 133 133 b high      0 #> 134 134 b high      0 #> 135 135 b high      0 #> 136 136 b high      0 #> 137 137 b high      0 #> 138 138 b high      1 #> 139 139 b high      0 #> 140 140 b high      0 #> 141 141 b high      0 #> 142 142 b high      0 #> 143 143 b high      0 #> 144 144 b high      0 #> 145 145 b high      0 #> 146 146 b high      0 #> 147 147 b high      0 #> 148 148 b high      0 #> 149 149 b high      0 #> 150 150 b high      0 #> 151 151 c high      0 #> 152 152 c high      0 #> 153 153 c high      0 #> 154 154 c high      1 #> 155 155 c high      0 #> 156 156 c high      0 #> 157 157 c high      0 #> 158 158 c high      0 #> 159 159 c high      0 #> 160 160 c high      0 #> 161 161 c high      0 #> 162 162 c high      0 #> 163 163 c high      0 #> 164 164 c high      0 #> 165 165 c high      0 #> 166 166 c high      0 #> 167 167 c high      0 #> 168 168 c high      0 #> 169 169 c high      1 #> 170 170 c high      0 #> 171 171 c high      1 #> 172 172 c high      0 #> 173 173 c high      0 #> 174 174 c high      0 #> 175 175 c high      0 #> 176 176 c high      0 #> 177 177 c high      0 #> 178 178 c high      0 #> 179 179 c high      1 #> 180 180 c high      0  # Examples of use of rBernoulli t <- rBernoulli(50, 0.1) mean(t) #> [1] 0.16"},{"path":"https://dcousin3.github.io/ANOPA/reference/summarize.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize — summarize","title":"summarize — summarize","text":"'summarize()' provides statistics table ANOPAobject. synonym 'summary()' (actions verbs, used verb).","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/summarize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize — summarize","text":"","code":"summarize(object, ...)"},{"path":"https://dcousin3.github.io/ANOPA/reference/summarize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize — summarize","text":"object object summarize ... ignored","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/summarize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summarize — summarize","text":"ANOPA table per articles.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/uncorrected.html","id":null,"dir":"Reference","previous_headings":"","what":"uncorrected — uncorrected","title":"uncorrected — uncorrected","text":"'uncorrected()' provides ANOPA table uncorrected statistics.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/uncorrected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"uncorrected — uncorrected","text":"","code":"uncorrected(object, ...)"},{"path":"https://dcousin3.github.io/ANOPA/reference/uncorrected.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"uncorrected — uncorrected","text":"object object explain ... ignored","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/uncorrected.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"uncorrected — uncorrected","text":"ANOPA table un-corrected test statistics. avoided, sample rather small.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/unitaryAlpha.html","id":null,"dir":"Reference","previous_headings":"","what":"unitary alpha — unitaryAlpha","title":"unitary alpha — unitaryAlpha","text":"function 'unitaryAlpha()' computes unitary alpha (lc23ANOPA). quantity novel way compute correlation matrix column measure line, subject. measure based Cronbach's alpha (labeled 'global alpha').","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/unitaryAlpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"unitary alpha — unitaryAlpha","text":"","code":"unitaryAlpha( m )"},{"path":"https://dcousin3.github.io/ANOPA/reference/unitaryAlpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"unitary alpha — unitaryAlpha","text":"m data matrix group observations.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/unitaryAlpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"unitary alpha — unitaryAlpha","text":"measure correlation -1 +1.","code":""},{"path":"https://dcousin3.github.io/ANOPA/reference/unitaryAlpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"unitary alpha — unitaryAlpha","text":"measure derived Cronbach' measure reliability shown lc23;textualANOPA.","code":""},{"path":[]},{"path":"https://dcousin3.github.io/ANOPA/reference/unitaryAlpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"unitary alpha — unitaryAlpha","text":"","code":"# Generate a random matrix (here binary entries) set.seed(42) N <- M <- 10 m <- matrix( runif(N*M), N, M)  # compute the unitary alpha from that random matrix unitaryAlpha(m) #> [1] 0.03055626"},{"path":"https://dcousin3.github.io/ANOPA/news/index.html","id":"anopa-022-february-2025","dir":"Changelog","previous_headings":"","what":"ANOPA 0.2.2 (February 2025)","title":"ANOPA 0.2.2 (February 2025)","text":"Implemented crange() complement cbind() Programmed emProportions()","code":""},{"path":"https://dcousin3.github.io/ANOPA/news/index.html","id":"anopa-021-december-2024","dir":"Changelog","previous_headings":"","what":"ANOPA 0.2.1 (December 2024)","title":"ANOPA 0.2.1 (December 2024)","text":"Corrected bug regarding conversion long involving wtoc()","code":""},{"path":"https://dcousin3.github.io/ANOPA/news/index.html","id":"anopa-020-november-2024","dir":"Changelog","previous_headings":"","what":"ANOPA 0.2.0 (November 2024)","title":"ANOPA 0.2.0 (November 2024)","text":"Allowed compiled format inputs anopa() repeated measures; Corrected bug GRP() mixed design; Corrected bug identity unitary Alpha column","code":""},{"path":"https://dcousin3.github.io/ANOPA/news/index.html","id":"anopa-013-march-2023","dir":"Changelog","previous_headings":"","what":"ANOPA 0.1.3 (March 2023)","title":"ANOPA 0.1.3 (March 2023)","text":"CRAN release: 2024-03-22 removed cat’s `’s","code":""},{"path":"https://dcousin3.github.io/ANOPA/news/index.html","id":"anopa-012-march-2023","dir":"Changelog","previous_headings":"","what":"ANOPA 0.1.2 (March 2023)","title":"ANOPA 0.1.2 (March 2023)","text":"added  speed tests; moved difference-adjustments within CI.Atrans() function.","code":""},{"path":"https://dcousin3.github.io/ANOPA/news/index.html","id":"anopa-011-march-2023","dir":"Changelog","previous_headings":"","what":"ANOPA 0.1.1 (March 2023)","title":"ANOPA 0.1.1 (March 2023)","text":"Beta release ANOPA CRAN.","code":""},{"path":"https://dcousin3.github.io/ANOPA/news/index.html","id":"anopa-010-january-2023","dir":"Changelog","previous_headings":"","what":"ANOPA 0.1.0 (January 2023)","title":"ANOPA 0.1.0 (January 2023)","text":"Beta release ANOPA GitHub.","code":""}]
